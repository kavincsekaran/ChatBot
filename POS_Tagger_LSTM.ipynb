{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load LSTM network and generate text\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "import h5py\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bc_df=pd.read_csv(\"/home/kavin/Silo/College Work/AI/DataSets/brown_tag_lines.txt\",sep=\"_\", names=(\"word\",\"pos_tag\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fulton</td>\n",
       "      <td>np</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>county</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grand</td>\n",
       "      <td>jj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jury</td>\n",
       "      <td>nn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word pos_tag\n",
       "0     the      at\n",
       "1  fulton      np\n",
       "2  county      nn\n",
       "3   grand      jj\n",
       "4    jury      nn"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-b4eb36d05c50>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-b4eb36d05c50>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    uniques_words=pd.Series(words).unique())\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "words=[]\n",
    "for word in bc_df.itertuples():\n",
    "    words.append(word[1].lower())\n",
    "uniques_words=pd.Series(words).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_words=pd.Series(bc_df[\"word\"]).unique()\n",
    "n_vocab=len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_of_words={}\n",
    "index_to_words={}\n",
    "index=0\n",
    "for word in unique_words:\n",
    "    bag_of_words[word]=index\n",
    "    index_to_words[index]=word\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_tags=bc_df[\"pos_tag\"].unique()\n",
    "bag_of_tags={}\n",
    "index_to_tags={}\n",
    "index=0\n",
    "for tag in unique_tags:\n",
    "    bag_of_tags[tag]=index\n",
    "    index_to_tags[index]=tag\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan: 312,\n",
       " '(': 61,\n",
       " ')': 62,\n",
       " '*': 50,\n",
       " '*-nc': 231,\n",
       " ',': 13,\n",
       " ',-nc': 213,\n",
       " '--': 56,\n",
       " '.': 11,\n",
       " '.-nc': 215,\n",
       " '.|sb01:1': 130,\n",
       " '.|sc01:1': 139,\n",
       " '.|sd01:1': 149,\n",
       " '.|se01:1': 152,\n",
       " '.|sf01:1': 161,\n",
       " '.|sg01:1': 179,\n",
       " '.|sh01:1': 202,\n",
       " '.|sj01:1': 204,\n",
       " '.|sk01:1': 262,\n",
       " '.|sl01:1': 280,\n",
       " '.|sm01:1': 287,\n",
       " '.|sn01:1': 288,\n",
       " '.|sp01:1': 307,\n",
       " '.|sr01:1': 311,\n",
       " ':': 52,\n",
       " 'abl': 74,\n",
       " 'abn': 44,\n",
       " 'abn-nc': 248,\n",
       " 'abx': 35,\n",
       " 'ap': 27,\n",
       " 'ap$': 104,\n",
       " 'ap+ap-nc': 257,\n",
       " 'ap-nc': 234,\n",
       " 'at': 0,\n",
       " 'at-nc': 172,\n",
       " 'be': 39,\n",
       " 'bed': 57,\n",
       " 'bed*': 114,\n",
       " 'bed-nc': 236,\n",
       " 'bedz': 18,\n",
       " 'bedz*': 66,\n",
       " 'bedz-nc': 225,\n",
       " 'beg': 59,\n",
       " 'bem': 83,\n",
       " 'bem*': 275,\n",
       " 'bem-nc': 253,\n",
       " 'ben': 20,\n",
       " 'ber': 28,\n",
       " 'ber*': 112,\n",
       " 'ber*-nc': 233,\n",
       " 'ber-nc': 208,\n",
       " 'bez': 41,\n",
       " 'bez*': 103,\n",
       " 'bez-nc': 245,\n",
       " 'cc': 17,\n",
       " 'cc-nc': 237,\n",
       " 'cd': 37,\n",
       " 'cd$': 111,\n",
       " 'cd-nc': 218,\n",
       " 'cs': 8,\n",
       " 'cs-nc': 241,\n",
       " 'do': 48,\n",
       " 'do*': 89,\n",
       " 'do+ppss': 299,\n",
       " 'do-nc': 235,\n",
       " 'dod': 26,\n",
       " 'dod*': 65,\n",
       " 'dod-nc': 251,\n",
       " 'doz': 63,\n",
       " 'doz*': 90,\n",
       " 'dt': 24,\n",
       " 'dt$': 76,\n",
       " 'dt+bez': 96,\n",
       " 'dt+bez-nc': 222,\n",
       " 'dt+md': 268,\n",
       " 'dt-nc': 191,\n",
       " 'dti': 9,\n",
       " 'dts': 30,\n",
       " 'dts+bez': 302,\n",
       " 'dtx': 82,\n",
       " 'ex': 51,\n",
       " 'ex+bez': 97,\n",
       " 'ex+hvd': 264,\n",
       " 'ex+hvz': 286,\n",
       " 'ex+md': 192,\n",
       " 'ex-nc': 232,\n",
       " 'fw-*': 125,\n",
       " 'fw-at': 106,\n",
       " 'fw-at+nn': 144,\n",
       " 'fw-at+np': 142,\n",
       " 'fw-be': 194,\n",
       " 'fw-ber': 181,\n",
       " 'fw-bez': 180,\n",
       " 'fw-cc': 100,\n",
       " 'fw-cd': 126,\n",
       " 'fw-cs': 188,\n",
       " 'fw-dt': 79,\n",
       " 'fw-dt+bez': 263,\n",
       " 'fw-dts': 203,\n",
       " 'fw-hv': 185,\n",
       " 'fw-in': 78,\n",
       " 'fw-in+at': 118,\n",
       " 'fw-in+at-t': 145,\n",
       " 'fw-in+nn': 93,\n",
       " 'fw-in+np': 170,\n",
       " 'fw-jj': 108,\n",
       " 'fw-jj-nc': 148,\n",
       " 'fw-jjr': 150,\n",
       " 'fw-jjt': 261,\n",
       " 'fw-nn': 80,\n",
       " 'fw-nn$': 151,\n",
       " 'fw-nn-nc': 173,\n",
       " 'fw-nns': 101,\n",
       " 'fw-nns-nc': 176,\n",
       " 'fw-np': 135,\n",
       " 'fw-nps': 187,\n",
       " 'fw-nr': 183,\n",
       " 'fw-od': 143,\n",
       " 'fw-od-nc': 308,\n",
       " 'fw-pn': 189,\n",
       " 'fw-pp$': 160,\n",
       " 'fw-pp$-nc': 121,\n",
       " 'fw-ppl': 133,\n",
       " 'fw-ppl+vbz': 201,\n",
       " 'fw-ppo': 138,\n",
       " 'fw-ppo+in': 190,\n",
       " 'fw-pps': 195,\n",
       " 'fw-ppss': 184,\n",
       " 'fw-ppss+hv': 309,\n",
       " 'fw-ql': 260,\n",
       " 'fw-rb': 147,\n",
       " 'fw-rb+cc': 198,\n",
       " 'fw-to+vb': 196,\n",
       " 'fw-uh': 193,\n",
       " 'fw-uh-nc': 159,\n",
       " 'fw-vb': 122,\n",
       " 'fw-vb-nc': 123,\n",
       " 'fw-vbd': 140,\n",
       " 'fw-vbg': 182,\n",
       " 'fw-vbn': 166,\n",
       " 'fw-vbz': 137,\n",
       " 'fw-wdt': 128,\n",
       " 'fw-wpo': 199,\n",
       " 'fw-wps': 200,\n",
       " 'hv': 29,\n",
       " 'hv*': 146,\n",
       " 'hv+to': 269,\n",
       " 'hv-nc': 212,\n",
       " 'hvd': 15,\n",
       " 'hvd*': 102,\n",
       " 'hvg': 81,\n",
       " 'hvn': 77,\n",
       " 'hvz': 43,\n",
       " 'hvz*': 117,\n",
       " 'hvz-nc': 217,\n",
       " 'in': 6,\n",
       " 'in+in': 298,\n",
       " 'in+ppo': 297,\n",
       " 'in-nc': 136,\n",
       " 'jj': 3,\n",
       " 'jj$': 197,\n",
       " 'jj+jj-nc': 256,\n",
       " 'jj-nc': 120,\n",
       " 'jjr': 40,\n",
       " 'jjr+cs': 175,\n",
       " 'jjr-nc': 124,\n",
       " 'jjs': 54,\n",
       " 'jjt': 34,\n",
       " 'jjt-nc': 250,\n",
       " 'md': 38,\n",
       " 'md*': 67,\n",
       " 'md+hv': 95,\n",
       " 'md+ppss': 271,\n",
       " 'md+to': 270,\n",
       " 'md-nc': 239,\n",
       " 'nn': 2,\n",
       " 'nn$': 42,\n",
       " 'nn+bez': 158,\n",
       " 'nn+hvd': 278,\n",
       " 'nn+hvz': 156,\n",
       " 'nn+in': 273,\n",
       " 'nn+md': 174,\n",
       " 'nn+nn-nc': 255,\n",
       " 'nn-nc': 119,\n",
       " 'nns': 10,\n",
       " 'nns$': 68,\n",
       " 'nns$-nc': 242,\n",
       " 'nns+md': 291,\n",
       " 'nns-nc': 162,\n",
       " 'np': 1,\n",
       " 'np$': 7,\n",
       " 'np+bez': 105,\n",
       " 'np+bez-nc': 247,\n",
       " 'np+hvz': 283,\n",
       " 'np+hvz-nc': 216,\n",
       " 'np+md': 295,\n",
       " 'np-nc': 169,\n",
       " 'nps': 53,\n",
       " 'nps$': 85,\n",
       " 'nps-nc': 254,\n",
       " 'nr': 5,\n",
       " 'nr$': 64,\n",
       " 'nr+md': 272,\n",
       " 'nr-nc': 210,\n",
       " 'nrs': 134,\n",
       " 'od': 58,\n",
       " 'od-nc': 246,\n",
       " 'pn': 45,\n",
       " 'pn$': 113,\n",
       " 'pn+bez': 276,\n",
       " 'pn+hvd': 310,\n",
       " 'pn+hvz': 107,\n",
       " 'pn+md': 266,\n",
       " 'pn-nc': 165,\n",
       " 'pp$': 47,\n",
       " 'pp$$': 94,\n",
       " 'pp$-nc': 221,\n",
       " 'ppl': 60,\n",
       " 'ppl-nc': 243,\n",
       " 'ppls': 72,\n",
       " 'ppo': 32,\n",
       " 'ppo-nc': 205,\n",
       " 'pps': 25,\n",
       " 'pps+bez': 87,\n",
       " 'pps+bez-nc': 238,\n",
       " 'pps+hvd': 177,\n",
       " 'pps+hvz': 75,\n",
       " 'pps+md': 99,\n",
       " 'pps-nc': 164,\n",
       " 'ppss': 46,\n",
       " 'ppss+bem': 70,\n",
       " 'ppss+ber': 69,\n",
       " 'ppss+ber-n': 206,\n",
       " 'ppss+ber-nc': 240,\n",
       " 'ppss+bez': 292,\n",
       " 'ppss+bez*': 293,\n",
       " 'ppss+hv': 98,\n",
       " 'ppss+hvd': 92,\n",
       " 'ppss+md': 84,\n",
       " 'ppss+md-nc': 230,\n",
       " 'ppss+vb': 289,\n",
       " 'ppss-nc': 163,\n",
       " 'ql': 33,\n",
       " 'ql-nc': 219,\n",
       " 'qlp': 91,\n",
       " 'rb': 23,\n",
       " 'rb$': 109,\n",
       " 'rb+bez': 115,\n",
       " 'rb+bez-nc': 223,\n",
       " 'rb+cs': 304,\n",
       " 'rb-nc': 131,\n",
       " 'rbr': 12,\n",
       " 'rbr+cs': 294,\n",
       " 'rbr-nc': 244,\n",
       " 'rbt': 71,\n",
       " 'rn': 132,\n",
       " 'rp': 55,\n",
       " 'rp+in': 274,\n",
       " 'rp-nc': 227,\n",
       " 'to': 21,\n",
       " 'to+vb': 296,\n",
       " 'to-nc': 209,\n",
       " 'uh': 88,\n",
       " 'uh-nc': 211,\n",
       " 'vb': 22,\n",
       " 'vb+at': 300,\n",
       " 'vb+in': 153,\n",
       " 'vb+jj-nc': 258,\n",
       " 'vb+ppo': 116,\n",
       " 'vb+rp': 178,\n",
       " 'vb+to': 267,\n",
       " 'vb+vb-nc': 259,\n",
       " 'vb-nc': 186,\n",
       " 'vbd': 4,\n",
       " 'vbd-nc': 226,\n",
       " 'vbg': 31,\n",
       " 'vbg+to': 155,\n",
       " 'vbg-nc': 229,\n",
       " 'vbn': 19,\n",
       " 'vbn+to': 157,\n",
       " 'vbn-nc': 171,\n",
       " 'vbz': 16,\n",
       " 'vbz-nc': 228,\n",
       " 'wdt': 14,\n",
       " 'wdt+ber': 306,\n",
       " 'wdt+ber+pp': 154,\n",
       " 'wdt+bez': 129,\n",
       " 'wdt+bez-nc': 214,\n",
       " 'wdt+do+pps': 303,\n",
       " 'wdt+dod': 279,\n",
       " 'wdt+hvz': 167,\n",
       " 'wdt-nc': 224,\n",
       " 'wp$': 86,\n",
       " 'wpo': 73,\n",
       " 'wpo-nc': 252,\n",
       " 'wps': 49,\n",
       " 'wps+bez': 110,\n",
       " 'wps+bez-nc': 220,\n",
       " 'wps+hvd': 277,\n",
       " 'wps+hvz': 265,\n",
       " 'wps+md': 168,\n",
       " 'wps-nc': 249,\n",
       " 'wql': 127,\n",
       " 'wrb': 36,\n",
       " 'wrb+ber': 290,\n",
       " 'wrb+bez': 141,\n",
       " 'wrb+do': 281,\n",
       " 'wrb+dod': 284,\n",
       " 'wrb+dod*': 305,\n",
       " 'wrb+doz': 301,\n",
       " 'wrb+in': 282,\n",
       " 'wrb+md': 285,\n",
       " 'wrb-nc': 207}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_index=[]\n",
    "word_index=[]\n",
    "for word in bc_df.itertuples():\n",
    "    word_index.append(bag_of_words[word[1]])\n",
    "    pos_index.append(bag_of_tags[word[2]])\n",
    "bc_df[\"word_index\"]=word_index\n",
    "bc_df[\"pos_tag_index\"]=pos_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "853100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_index=int(math.floor(len(bc_df)*0.75))\n",
    "split_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = bc_df[:split_index], bc_df[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "train[\"pos_tag_index\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  10000\n"
     ]
    }
   ],
   "source": [
    "seq_length = 10\n",
    "dataX = []\n",
    "dataY = []\n",
    "input_line=[]\n",
    "output_line=[]\n",
    "for i in range(0, 10000, 1):\n",
    "    input_line=train[\"pos_tag_index\"][i:i+seq_length]\n",
    "    output_line=train[\"pos_tag_index\"][i+seq_length]\n",
    "    dataX.append(input_line)\n",
    "    dataY.append(output_line)\n",
    "n_patterns = len(dataX)\n",
    "print \"Total Patterns: \", n_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('pos_bag_of_tags.json', 'w') as fp:\n",
    "    json.dump(bag_of_tags, fp)\n",
    "with open('pos_bag_of_words.json', 'w') as fp:\n",
    "    json.dump(bag_of_words, fp)\n",
    "with open('pos_index_to_tags.json', 'w') as fp:\n",
    "    json.dump(bag_of_tags, fp)\n",
    "with open('pos_index_to_words.json', 'w') as fp:\n",
    "    json.dump(bag_of_words, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (len(dataX), 10, 1))\n",
    "    # normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 9984/10000 [============================>.] - ETA: 0s - loss: 3.4156Epoch 00000: loss improved from inf to 3.41520, saving model to Donna Files/tagger_weights-improvement-00-3.4152.hdf5\n",
      "10000/10000 [==============================] - 3s - loss: 3.4152     \n",
      "Epoch 2/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1772Epoch 00001: loss improved from 3.41520 to 3.17568, saving model to Donna Files/tagger_weights-improvement-01-3.1757.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1757     \n",
      "Epoch 3/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1669Epoch 00002: loss improved from 3.17568 to 3.16674, saving model to Donna Files/tagger_weights-improvement-02-3.1667.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1667     \n",
      "Epoch 4/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1656Epoch 00003: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1686     \n",
      "Epoch 5/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1697Epoch 00004: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1692     \n",
      "Epoch 6/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1604Epoch 00005: loss improved from 3.16674 to 3.16080, saving model to Donna Files/tagger_weights-improvement-05-3.1608.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1608     \n",
      "Epoch 7/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1651Epoch 00006: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1632     \n",
      "Epoch 8/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1599Epoch 00007: loss improved from 3.16080 to 3.16012, saving model to Donna Files/tagger_weights-improvement-07-3.1601.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1601     \n",
      "Epoch 9/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1586Epoch 00008: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1603     \n",
      "Epoch 10/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1628Epoch 00009: loss improved from 3.16012 to 3.15930, saving model to Donna Files/tagger_weights-improvement-09-3.1593.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1593     \n",
      "Epoch 11/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1583Epoch 00010: loss improved from 3.15930 to 3.15620, saving model to Donna Files/tagger_weights-improvement-10-3.1562.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1562     \n",
      "Epoch 12/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1605- EEpoch 00011: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1601     \n",
      "Epoch 13/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1560Epoch 00012: loss improved from 3.15620 to 3.15400, saving model to Donna Files/tagger_weights-improvement-12-3.1540.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1540     \n",
      "Epoch 14/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1540Epoch 00013: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1542     \n",
      "Epoch 15/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1544Epoch 00014: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1563     \n",
      "Epoch 16/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1578Epoch 00015: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1566     \n",
      "Epoch 17/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1530Epoch 00016: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1545     \n",
      "Epoch 18/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1587Epoch 00017: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1569     \n",
      "Epoch 19/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1533Epoch 00018: loss improved from 3.15400 to 3.15396, saving model to Donna Files/tagger_weights-improvement-18-3.1540.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1540     \n",
      "Epoch 20/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1512Epoch 00019: loss improved from 3.15396 to 3.15290, saving model to Donna Files/tagger_weights-improvement-19-3.1529.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1529     \n",
      "Epoch 21/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1523Epoch 00020: loss improved from 3.15290 to 3.15270, saving model to Donna Files/tagger_weights-improvement-20-3.1527.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1527     \n",
      "Epoch 22/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1545Epoch 00021: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1552     \n",
      "Epoch 23/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1515Epoch 00022: loss improved from 3.15270 to 3.15165, saving model to Donna Files/tagger_weights-improvement-22-3.1517.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1517     \n",
      "Epoch 24/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1553Epoch 00023: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1545     \n",
      "Epoch 25/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1559Epoch 00024: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1541     \n",
      "Epoch 26/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1519Epoch 00025: loss improved from 3.15165 to 3.15088, saving model to Donna Files/tagger_weights-improvement-25-3.1509.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1509     \n",
      "Epoch 27/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1525Epoch 00026: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1513     \n",
      "Epoch 28/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1518Epoch 00027: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1511     \n",
      "Epoch 29/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1526Epoch 00028: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1514     \n",
      "Epoch 30/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1506Epoch 00029: loss improved from 3.15088 to 3.15072, saving model to Donna Files/tagger_weights-improvement-29-3.1507.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1507     \n",
      "Epoch 31/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1498Epoch 00030: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1517     \n",
      "Epoch 32/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1499Epoch 00031: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1516     \n",
      "Epoch 33/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1493Epoch 00032: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1517     \n",
      "Epoch 34/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1511Epoch 00033: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1525     \n",
      "Epoch 35/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1486Epoch 00034: loss improved from 3.15072 to 3.15001, saving model to Donna Files/tagger_weights-improvement-34-3.1500.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1500     \n",
      "Epoch 36/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1522Epoch 00035: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1524     \n",
      "Epoch 37/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1515Epoch 00036: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1505     \n",
      "Epoch 38/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1504Epoch 00037: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1507     \n",
      "Epoch 39/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1517Epoch 00038: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1503     \n",
      "Epoch 40/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1508Epoch 00039: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1507     \n",
      "Epoch 41/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1501Epoch 00040: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1502     \n",
      "Epoch 42/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1512Epoch 00041: loss improved from 3.15001 to 3.14919, saving model to Donna Files/tagger_weights-improvement-41-3.1492.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1492     \n",
      "Epoch 43/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1472Epoch 00042: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1508     \n",
      "Epoch 44/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1484Epoch 00043: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1493     \n",
      "Epoch 45/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1481Epoch 00044: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1516     \n",
      "Epoch 46/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1517Epoch 00045: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1512     \n",
      "Epoch 47/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1508Epoch 00046: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1508     \n",
      "Epoch 48/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1474Epoch 00047: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1506     \n",
      "Epoch 49/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1501Epoch 00048: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1499     \n",
      "Epoch 50/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1526Epoch 00049: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1508     \n",
      "Epoch 51/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1475Epoch 00050: loss improved from 3.14919 to 3.14861, saving model to Donna Files/tagger_weights-improvement-50-3.1486.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1486     \n",
      "Epoch 52/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1517Epoch 00051: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1509     \n",
      "Epoch 53/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1503Epoch 00052: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1505     \n",
      "Epoch 54/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1500Epoch 00053: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1494     \n",
      "Epoch 55/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1505Epoch 00054: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1501     \n",
      "Epoch 56/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1483Epoch 00055: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1488     \n",
      "Epoch 57/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1496Epoch 00056: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1497     \n",
      "Epoch 58/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1502Epoch 00057: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1487     \n",
      "Epoch 59/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1501Epoch 00058: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1494     \n",
      "Epoch 60/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1491Epoch 00059: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1500     \n",
      "Epoch 61/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1508Epoch 00060: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1488     \n",
      "Epoch 62/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1517Epoch 00061: loss improved from 3.14861 to 3.14857, saving model to Donna Files/tagger_weights-improvement-61-3.1486.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1486     \n",
      "Epoch 63/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1536Epoch 00062: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1500     \n",
      "Epoch 64/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1519Epoch 00063: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1493     \n",
      "Epoch 65/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1467Epoch 00064: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1488     \n",
      "Epoch 66/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1466Epoch 00065: loss improved from 3.14857 to 3.14782, saving model to Donna Files/tagger_weights-improvement-65-3.1478.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1478     \n",
      "Epoch 67/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1462Epoch 00066: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1483     \n",
      "Epoch 68/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1485Epoch 00067: loss improved from 3.14782 to 3.14733, saving model to Donna Files/tagger_weights-improvement-67-3.1473.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1473     \n",
      "Epoch 69/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1477Epoch 00068: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1485     \n",
      "Epoch 70/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1495Epoch 00069: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1489     \n",
      "Epoch 71/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1471Epoch 00070: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1489     \n",
      "Epoch 72/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1471Epoch 00071: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1483     \n",
      "Epoch 73/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1459Epoch 00072: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1478     \n",
      "Epoch 74/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1479Epoch 00073: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1478     \n",
      "Epoch 75/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1465Epoch 00074: loss improved from 3.14733 to 3.14679, saving model to Donna Files/tagger_weights-improvement-74-3.1468.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1468     \n",
      "Epoch 76/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1471Epoch 00075: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1485     \n",
      "Epoch 77/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1485Epoch 00076: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1474     \n",
      "Epoch 78/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1481Epoch 00077: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s - loss: 3.1488     \n",
      "Epoch 79/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1449Epoch 00078: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1474     \n",
      "Epoch 80/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1497Epoch 00079: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1494     \n",
      "Epoch 81/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1474Epoch 00080: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1484     \n",
      "Epoch 82/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1472Epoch 00081: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1493     \n",
      "Epoch 83/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1449Epoch 00082: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1477     \n",
      "Epoch 84/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1474Epoch 00083: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1479     \n",
      "Epoch 85/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1492Epoch 00084: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1485     \n",
      "Epoch 86/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1495Epoch 00085: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1487     \n",
      "Epoch 87/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1478Epoch 00086: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1477     \n",
      "Epoch 88/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1465Epoch 00087: loss improved from 3.14679 to 3.14669, saving model to Donna Files/tagger_weights-improvement-87-3.1467.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1467     \n",
      "Epoch 89/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1458Epoch 00088: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1476     \n",
      "Epoch 90/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1490Epoch 00089: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1482     \n",
      "Epoch 91/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1526Epoch 00090: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1495     \n",
      "Epoch 92/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1500Epoch 00091: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1480     \n",
      "Epoch 93/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1476Epoch 00092: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1477     \n",
      "Epoch 94/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1478Epoch 00093: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1479     \n",
      "Epoch 95/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1478Epoch 00094: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1482     \n",
      "Epoch 96/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1469Epoch 00095: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1478     \n",
      "Epoch 97/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1506Epoch 00096: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1477     \n",
      "Epoch 98/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1466Epoch 00097: loss improved from 3.14669 to 3.14663, saving model to Donna Files/tagger_weights-improvement-97-3.1466.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1466     \n",
      "Epoch 99/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1476Epoch 00098: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1470     \n",
      "Epoch 100/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1489Epoch 00099: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1492     \n",
      "Epoch 101/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1469Epoch 00100: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1475     \n",
      "Epoch 102/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1478Epoch 00101: loss improved from 3.14663 to 3.14645, saving model to Donna Files/tagger_weights-improvement-101-3.1465.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1465     \n",
      "Epoch 103/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1444Epoch 00102: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1477     \n",
      "Epoch 104/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1451Epoch 00103: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1470     \n",
      "Epoch 105/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1486Epoch 00104: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1488     \n",
      "Epoch 106/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1488Epoch 00105: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1471     \n",
      "Epoch 107/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1483Epoch 00106: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1471     \n",
      "Epoch 108/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1477Epoch 00107: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1480     \n",
      "Epoch 109/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1481- ETA: 0s - loEpoch 00108: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1466     \n",
      "Epoch 110/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1461Epoch 00109: loss improved from 3.14645 to 3.14622, saving model to Donna Files/tagger_weights-improvement-109-3.1462.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1462     \n",
      "Epoch 111/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1492Epoch 00110: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1483     \n",
      "Epoch 112/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1467Epoch 00111: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1477     \n",
      "Epoch 113/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1486Epoch 00112: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1481     \n",
      "Epoch 114/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1450Epoch 00113: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1469     \n",
      "Epoch 115/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1466Epoch 00114: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1468     \n",
      "Epoch 116/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1474Epoch 00115: loss improved from 3.14622 to 3.14614, saving model to Donna Files/tagger_weights-improvement-115-3.1461.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1461     \n",
      "Epoch 117/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1446Epoch 00116: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1466     \n",
      "Epoch 118/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1475Epoch 00117: loss improved from 3.14614 to 3.14596, saving model to Donna Files/tagger_weights-improvement-117-3.1460.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1460     \n",
      "Epoch 119/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1486Epoch 00118: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1476     \n",
      "Epoch 120/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1428Epoch 00119: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1476     \n",
      "Epoch 121/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1450Epoch 00120: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1466     \n",
      "Epoch 122/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1454Epoch 00121: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1468     \n",
      "Epoch 123/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1490Epoch 00122: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1480     \n",
      "Epoch 124/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1469Epoch 00123: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1473     \n",
      "Epoch 125/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1466Epoch 00124: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1466     \n",
      "Epoch 126/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1462Epoch 00125: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1475     \n",
      "Epoch 127/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1504Epoch 00126: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1465     \n",
      "Epoch 128/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1472Epoch 00127: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1485     \n",
      "Epoch 129/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1483- ETA: 0s - loss: Epoch 00128: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1464     \n",
      "Epoch 130/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1481Epoch 00129: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1472     \n",
      "Epoch 131/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1472Epoch 00130: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1470     \n",
      "Epoch 132/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1490Epoch 00131: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1462     \n",
      "Epoch 133/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1467Epoch 00132: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1473     \n",
      "Epoch 134/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1456Epoch 00133: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1467     \n",
      "Epoch 135/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1473Epoch 00134: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1462     \n",
      "Epoch 136/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1487Epoch 00135: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1473     \n",
      "Epoch 137/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1457Epoch 00136: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1471     \n",
      "Epoch 138/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1440Epoch 00137: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1462     \n",
      "Epoch 139/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1470Epoch 00138: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1460     \n",
      "Epoch 140/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1473Epoch 00139: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1476     \n",
      "Epoch 141/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1485Epoch 00140: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1470     \n",
      "Epoch 142/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1472Epoch 00141: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1469     \n",
      "Epoch 143/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1469Epoch 00142: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1474     \n",
      "Epoch 144/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1478Epoch 00143: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1467     \n",
      "Epoch 145/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1466Epoch 00144: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1477     \n",
      "Epoch 146/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1439Epoch 00145: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1476     \n",
      "Epoch 147/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1493Epoch 00146: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1466     \n",
      "Epoch 148/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1470Epoch 00147: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1468     \n",
      "Epoch 149/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1457Epoch 00148: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1466     \n",
      "Epoch 150/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1455Epoch 00149: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1468     \n",
      "Epoch 151/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1451Epoch 00150: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1467     \n",
      "Epoch 152/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1458Epoch 00151: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1465     \n",
      "Epoch 153/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1467Epoch 00152: loss improved from 3.14596 to 3.14587, saving model to Donna Files/tagger_weights-improvement-152-3.1459.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1459     \n",
      "Epoch 154/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1500Epoch 00153: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1471     \n",
      "Epoch 155/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1495Epoch 00154: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1469     \n",
      "Epoch 156/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1452Epoch 00155: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1478     \n",
      "Epoch 157/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1482Epoch 00156: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1466     \n",
      "Epoch 158/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1449Epoch 00157: loss improved from 3.14587 to 3.14532, saving model to Donna Files/tagger_weights-improvement-157-3.1453.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1453     \n",
      "Epoch 159/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1487Epoch 00158: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1457     \n",
      "Epoch 160/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1495Epoch 00159: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1469     \n",
      "Epoch 161/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1449Epoch 00160: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s - loss: 3.1471     \n",
      "Epoch 162/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1439Epoch 00161: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1460     \n",
      "Epoch 163/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1449Epoch 00162: loss improved from 3.14532 to 3.14532, saving model to Donna Files/tagger_weights-improvement-162-3.1453.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1453     \n",
      "Epoch 164/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1476Epoch 00163: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1455     \n",
      "Epoch 165/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1451Epoch 00164: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1461     \n",
      "Epoch 166/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1446Epoch 00165: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1462     \n",
      "Epoch 167/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1464Epoch 00166: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1472     \n",
      "Epoch 168/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1486Epoch 00167: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1468     \n",
      "Epoch 169/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1478Epoch 00168: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1462     \n",
      "Epoch 170/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1455Epoch 00169: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1467     \n",
      "Epoch 171/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1446Epoch 00170: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1465     \n",
      "Epoch 172/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1443Epoch 00171: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1467     \n",
      "Epoch 173/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1490Epoch 00172: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1460     \n",
      "Epoch 174/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1494Epoch 00173: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1473     \n",
      "Epoch 175/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1480Epoch 00174: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1469     \n",
      "Epoch 176/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1460Epoch 00175: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1463     \n",
      "Epoch 177/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1441Epoch 00176: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1463     \n",
      "Epoch 178/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1477Epoch 00177: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1461     \n",
      "Epoch 179/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1453Epoch 00178: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1461     \n",
      "Epoch 180/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1437Epoch 00179: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1463     \n",
      "Epoch 181/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1453Epoch 00180: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1457     \n",
      "Epoch 182/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1464Epoch 00181: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1465     \n",
      "Epoch 183/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1467Epoch 00182: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1459     \n",
      "Epoch 184/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1451Epoch 00183: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1454     \n",
      "Epoch 185/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1482Epoch 00184: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1465     \n",
      "Epoch 186/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1439Epoch 00185: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1457     \n",
      "Epoch 187/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1457Epoch 00186: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1469     \n",
      "Epoch 188/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1444Epoch 00187: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1460     \n",
      "Epoch 189/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1429Epoch 00188: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1458     \n",
      "Epoch 190/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1452Epoch 00189: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1462     \n",
      "Epoch 191/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1461Epoch 00190: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1465     \n",
      "Epoch 192/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1457Epoch 00191: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1466     \n",
      "Epoch 193/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1461Epoch 00192: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1465     \n",
      "Epoch 194/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1461Epoch 00193: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1454     \n",
      "Epoch 195/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1494Epoch 00194: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1468     \n",
      "Epoch 196/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1470Epoch 00195: loss improved from 3.14532 to 3.14481, saving model to Donna Files/tagger_weights-improvement-195-3.1448.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1448     \n",
      "Epoch 197/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1436Epoch 00196: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1456     \n",
      "Epoch 198/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1453Epoch 00197: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1451     \n",
      "Epoch 199/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1466Epoch 00198: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1455     \n",
      "Epoch 200/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1442Epoch 00199: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1455     \n",
      "Epoch 201/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1448Epoch 00200: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1458     \n",
      "Epoch 202/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1481Epoch 00201: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1461     \n",
      "Epoch 203/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1475Epoch 00202: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1457     \n",
      "Epoch 204/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1443Epoch 00203: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1452     \n",
      "Epoch 205/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1459Epoch 00204: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1460     \n",
      "Epoch 206/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1454Epoch 00205: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1456     \n",
      "Epoch 207/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1470Epoch 00206: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1462     \n",
      "Epoch 208/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1470Epoch 00207: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1459     \n",
      "Epoch 209/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1456Epoch 00208: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1448     \n",
      "Epoch 210/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1436Epoch 00209: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1454     \n",
      "Epoch 211/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1476Epoch 00210: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1467     \n",
      "Epoch 212/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1493Epoch 00211: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1465     \n",
      "Epoch 213/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1461Epoch 00212: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1451     \n",
      "Epoch 214/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1447Epoch 00213: loss improved from 3.14481 to 3.14442, saving model to Donna Files/tagger_weights-improvement-213-3.1444.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1444     \n",
      "Epoch 215/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1463Epoch 00214: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1454     \n",
      "Epoch 216/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1481Epoch 00215: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1466     \n",
      "Epoch 217/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1441Epoch 00216: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1453     \n",
      "Epoch 218/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1451Epoch 00217: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1453     \n",
      "Epoch 219/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1491Epoch 00218: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1462     \n",
      "Epoch 220/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1470Epoch 00219: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1448     \n",
      "Epoch 221/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1452Epoch 00220: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1447     \n",
      "Epoch 222/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1456Epoch 00221: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1459     \n",
      "Epoch 223/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1465- ETA: 1Epoch 00222: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1465     \n",
      "Epoch 224/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1440Epoch 00223: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1448     \n",
      "Epoch 225/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1483Epoch 00224: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1458     \n",
      "Epoch 226/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1459Epoch 00225: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1454     \n",
      "Epoch 227/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1448Epoch 00226: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1450     \n",
      "Epoch 228/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1461Epoch 00227: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1456     \n",
      "Epoch 229/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1463Epoch 00228: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1450     \n",
      "Epoch 230/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1416Epoch 00229: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1449     \n",
      "Epoch 231/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1485Epoch 00230: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1445     \n",
      "Epoch 232/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1465Epoch 00231: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1454     \n",
      "Epoch 233/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1442Epoch 00232: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1451     \n",
      "Epoch 234/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1458Epoch 00233: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1446     \n",
      "Epoch 235/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1466Epoch 00234: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1447     \n",
      "Epoch 236/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1428Epoch 00235: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1445     \n",
      "Epoch 237/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1517Epoch 00236: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1537     \n",
      "Epoch 238/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1449Epoch 00237: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1449     \n",
      "Epoch 239/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1460Epoch 00238: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1462     \n",
      "Epoch 240/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1408Epoch 00239: loss improved from 3.14442 to 3.14438, saving model to Donna Files/tagger_weights-improvement-239-3.1444.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1444     \n",
      "Epoch 241/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1462Epoch 00240: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1452     \n",
      "Epoch 242/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1453Epoch 00241: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1449     \n",
      "Epoch 243/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1457Epoch 00242: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1451     \n",
      "Epoch 244/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1434Epoch 00243: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1446     \n",
      "Epoch 245/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1454Epoch 00244: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1450     \n",
      "Epoch 246/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1464Epoch 00245: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s - loss: 3.1450     \n",
      "Epoch 247/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1439Epoch 00246: loss improved from 3.14438 to 3.14424, saving model to Donna Files/tagger_weights-improvement-246-3.1442.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1442     \n",
      "Epoch 248/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1449- EEpoch 00247: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1450     \n",
      "Epoch 249/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1468Epoch 00248: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1452     \n",
      "Epoch 250/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1447Epoch 00249: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1450     \n",
      "Epoch 251/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1475Epoch 00250: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1446     \n",
      "Epoch 252/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1431Epoch 00251: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1444     \n",
      "Epoch 253/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1423Epoch 00252: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1446     \n",
      "Epoch 254/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1459Epoch 00253: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1448     \n",
      "Epoch 255/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1459Epoch 00254: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1446     \n",
      "Epoch 256/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1466Epoch 00255: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1456     \n",
      "Epoch 257/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1444- ETA: 0s - Epoch 00256: loss improved from 3.14424 to 3.14339, saving model to Donna Files/tagger_weights-improvement-256-3.1434.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1434     \n",
      "Epoch 258/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1458Epoch 00257: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1446     \n",
      "Epoch 259/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1429Epoch 00258: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1444     \n",
      "Epoch 260/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1426Epoch 00259: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1434     \n",
      "Epoch 261/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1456Epoch 00260: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1450     \n",
      "Epoch 262/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1464Epoch 00261: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1443     \n",
      "Epoch 263/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1441Epoch 00262: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1442     \n",
      "Epoch 264/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1423Epoch 00263: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1438     \n",
      "Epoch 265/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1453Epoch 00264: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1450     \n",
      "Epoch 266/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1428- ETAEpoch 00265: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1448     \n",
      "Epoch 267/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1439Epoch 00266: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1441     \n",
      "Epoch 268/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1457Epoch 00267: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1449     \n",
      "Epoch 269/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1453Epoch 00268: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1439     \n",
      "Epoch 270/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1434Epoch 00269: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1440     \n",
      "Epoch 271/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1436Epoch 00270: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1446     \n",
      "Epoch 272/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1456Epoch 00271: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1450     \n",
      "Epoch 273/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1437Epoch 00272: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1442     \n",
      "Epoch 274/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1442Epoch 00273: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1440     \n",
      "Epoch 275/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1430Epoch 00274: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1439     \n",
      "Epoch 276/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1426Epoch 00275: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1450     \n",
      "Epoch 277/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1447Epoch 00276: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1446     \n",
      "Epoch 278/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1455Epoch 00277: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1446     \n",
      "Epoch 279/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1444Epoch 00278: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1440     \n",
      "Epoch 280/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1424Epoch 00279: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1441     \n",
      "Epoch 281/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1433Epoch 00280: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1434     \n",
      "Epoch 282/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1438Epoch 00281: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1445     \n",
      "Epoch 283/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1416Epoch 00282: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1444     \n",
      "Epoch 284/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1399Epoch 00283: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1440     \n",
      "Epoch 285/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1440Epoch 00284: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1443     \n",
      "Epoch 286/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1429Epoch 00285: loss improved from 3.14339 to 3.14325, saving model to Donna Files/tagger_weights-improvement-285-3.1432.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1432     \n",
      "Epoch 287/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1416Epoch 00286: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1440     \n",
      "Epoch 288/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1448Epoch 00287: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1437     \n",
      "Epoch 289/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1455Epoch 00288: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1436     \n",
      "Epoch 290/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1424Epoch 00289: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1436     \n",
      "Epoch 291/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1438Epoch 00290: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1440     \n",
      "Epoch 292/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1427Epoch 00291: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1436     \n",
      "Epoch 293/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1414Epoch 00292: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1435     \n",
      "Epoch 294/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1435Epoch 00293: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1443     \n",
      "Epoch 295/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1450Epoch 00294: loss improved from 3.14325 to 3.14274, saving model to Donna Files/tagger_weights-improvement-294-3.1427.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1427     \n",
      "Epoch 296/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1466Epoch 00295: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1439     \n",
      "Epoch 297/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1442Epoch 00296: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1436     \n",
      "Epoch 298/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1434Epoch 00297: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1434     \n",
      "Epoch 299/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1404Epoch 00298: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1432     \n",
      "Epoch 300/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1429Epoch 00299: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1449     \n",
      "Epoch 301/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1435Epoch 00300: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1432     \n",
      "Epoch 302/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1433Epoch 00301: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1431     \n",
      "Epoch 303/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1408Epoch 00302: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1429     \n",
      "Epoch 304/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1433Epoch 00303: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1434     \n",
      "Epoch 305/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1448Epoch 00304: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1439     \n",
      "Epoch 306/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1442Epoch 00305: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1437     \n",
      "Epoch 307/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1386Epoch 00306: loss improved from 3.14274 to 3.14160, saving model to Donna Files/tagger_weights-improvement-306-3.1416.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1416     \n",
      "Epoch 308/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1424- ETA: 0s - lEpoch 00307: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1430     \n",
      "Epoch 309/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1394Epoch 00308: loss improved from 3.14160 to 3.14155, saving model to Donna Files/tagger_weights-improvement-308-3.1416.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1416     \n",
      "Epoch 310/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1419Epoch 00309: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1430     \n",
      "Epoch 311/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1413Epoch 00310: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1423     \n",
      "Epoch 312/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1415Epoch 00311: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1432     \n",
      "Epoch 313/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1427Epoch 00312: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1424     \n",
      "Epoch 314/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1429Epoch 00313: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1423     \n",
      "Epoch 315/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1408Epoch 00314: loss improved from 3.14155 to 3.14149, saving model to Donna Files/tagger_weights-improvement-314-3.1415.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1415     \n",
      "Epoch 316/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1409Epoch 00315: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1425     \n",
      "Epoch 317/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1405Epoch 00316: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1422     \n",
      "Epoch 318/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1431Epoch 00317: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1427     \n",
      "Epoch 319/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1436Epoch 00318: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1431     \n",
      "Epoch 320/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1426Epoch 00319: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1418     \n",
      "Epoch 321/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1405Epoch 00320: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1419     \n",
      "Epoch 322/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1415Epoch 00321: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1417     \n",
      "Epoch 323/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1401Epoch 00322: loss improved from 3.14149 to 3.14124, saving model to Donna Files/tagger_weights-improvement-322-3.1412.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1412     \n",
      "Epoch 324/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1382Epoch 00323: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1417     \n",
      "Epoch 325/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1423Epoch 00324: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1415     \n",
      "Epoch 326/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1417Epoch 00325: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1417     \n",
      "Epoch 327/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1424Epoch 00326: loss improved from 3.14124 to 3.14087, saving model to Donna Files/tagger_weights-improvement-326-3.1409.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1409     \n",
      "Epoch 328/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1414Epoch 00327: loss improved from 3.14087 to 3.14083, saving model to Donna Files/tagger_weights-improvement-327-3.1408.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s - loss: 3.1408     \n",
      "Epoch 329/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1432Epoch 00328: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1424     \n",
      "Epoch 330/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1404- ETA: 1Epoch 00329: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1409     \n",
      "Epoch 331/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1432Epoch 00330: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1423     \n",
      "Epoch 332/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1427Epoch 00331: loss improved from 3.14083 to 3.14028, saving model to Donna Files/tagger_weights-improvement-331-3.1403.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1403     \n",
      "Epoch 333/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1400Epoch 00332: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1403     \n",
      "Epoch 334/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1411Epoch 00333: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1416     \n",
      "Epoch 335/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1389Epoch 00334: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1410     \n",
      "Epoch 336/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1423Epoch 00335: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1408     \n",
      "Epoch 337/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1402Epoch 00336: loss improved from 3.14028 to 3.13926, saving model to Donna Files/tagger_weights-improvement-336-3.1393.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1393     \n",
      "Epoch 338/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1374Epoch 00337: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1393     \n",
      "Epoch 339/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1409Epoch 00338: loss improved from 3.13926 to 3.13890, saving model to Donna Files/tagger_weights-improvement-338-3.1389.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1389     \n",
      "Epoch 340/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1396Epoch 00339: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1396     \n",
      "Epoch 341/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1390Epoch 00340: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1389     \n",
      "Epoch 342/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1383Epoch 00341: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1393     \n",
      "Epoch 343/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1398Epoch 00342: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1393     \n",
      "Epoch 344/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1401Epoch 00343: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1394     \n",
      "Epoch 345/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1404Epoch 00344: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1396     \n",
      "Epoch 346/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1410Epoch 00345: loss improved from 3.13890 to 3.13870, saving model to Donna Files/tagger_weights-improvement-345-3.1387.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1387     \n",
      "Epoch 347/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1386Epoch 00346: loss improved from 3.13870 to 3.13638, saving model to Donna Files/tagger_weights-improvement-346-3.1364.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1364     \n",
      "Epoch 348/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1378Epoch 00347: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1387     \n",
      "Epoch 349/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1387Epoch 00348: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1385     \n",
      "Epoch 350/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1364Epoch 00349: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1384     \n",
      "Epoch 351/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1392Epoch 00350: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1385     \n",
      "Epoch 352/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1377Epoch 00351: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1386     \n",
      "Epoch 353/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1390Epoch 00352: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1392     \n",
      "Epoch 354/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1355Epoch 00353: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1371     \n",
      "Epoch 355/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1371Epoch 00354: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1376     \n",
      "Epoch 356/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1367Epoch 00355: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1367     \n",
      "Epoch 357/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1377Epoch 00356: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1372     \n",
      "Epoch 358/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1383Epoch 00357: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1373     \n",
      "Epoch 359/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1366Epoch 00358: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1369     \n",
      "Epoch 360/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1362Epoch 00359: loss improved from 3.13638 to 3.13622, saving model to Donna Files/tagger_weights-improvement-359-3.1362.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1362     \n",
      "Epoch 361/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1345Epoch 00360: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1368     \n",
      "Epoch 362/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1352Epoch 00361: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1364     \n",
      "Epoch 363/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1363Epoch 00362: loss improved from 3.13622 to 3.13597, saving model to Donna Files/tagger_weights-improvement-362-3.1360.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1360     \n",
      "Epoch 364/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1350Epoch 00363: loss improved from 3.13597 to 3.13505, saving model to Donna Files/tagger_weights-improvement-363-3.1351.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1351     \n",
      "Epoch 365/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1341Epoch 00364: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1352     \n",
      "Epoch 366/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1365Epoch 00365: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1356     \n",
      "Epoch 367/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1357Epoch 00366: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1357     \n",
      "Epoch 368/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1370Epoch 00367: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1353     \n",
      "Epoch 369/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1364Epoch 00368: loss improved from 3.13505 to 3.13445, saving model to Donna Files/tagger_weights-improvement-368-3.1344.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1344     \n",
      "Epoch 370/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1370Epoch 00369: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1354     \n",
      "Epoch 371/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1358Epoch 00370: loss improved from 3.13445 to 3.13439, saving model to Donna Files/tagger_weights-improvement-370-3.1344.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1344     \n",
      "Epoch 372/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1340Epoch 00371: loss improved from 3.13439 to 3.13353, saving model to Donna Files/tagger_weights-improvement-371-3.1335.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1335     \n",
      "Epoch 373/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1343Epoch 00372: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1352     \n",
      "Epoch 374/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1370Epoch 00373: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1350     \n",
      "Epoch 375/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1328Epoch 00374: loss improved from 3.13353 to 3.13336, saving model to Donna Files/tagger_weights-improvement-374-3.1334.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1334     \n",
      "Epoch 376/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1371Epoch 00375: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1351     \n",
      "Epoch 377/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1337- ETA:  - ETA: 0s - loss: 3Epoch 00376: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1337     \n",
      "Epoch 378/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1308Epoch 00377: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1336     \n",
      "Epoch 379/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1324Epoch 00378: loss improved from 3.13336 to 3.13323, saving model to Donna Files/tagger_weights-improvement-378-3.1332.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1332     \n",
      "Epoch 380/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1359Epoch 00379: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1337     \n",
      "Epoch 381/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1323Epoch 00380: loss improved from 3.13323 to 3.13276, saving model to Donna Files/tagger_weights-improvement-380-3.1328.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1328     \n",
      "Epoch 382/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1309Epoch 00381: loss improved from 3.13276 to 3.13246, saving model to Donna Files/tagger_weights-improvement-381-3.1325.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1325     \n",
      "Epoch 383/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1329Epoch 00382: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1330     \n",
      "Epoch 384/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1332Epoch 00383: loss improved from 3.13246 to 3.13153, saving model to Donna Files/tagger_weights-improvement-383-3.1315.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1315     \n",
      "Epoch 385/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1317Epoch 00384: loss improved from 3.13153 to 3.13085, saving model to Donna Files/tagger_weights-improvement-384-3.1308.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1308     \n",
      "Epoch 386/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1362Epoch 00385: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1339     \n",
      "Epoch 387/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1299Epoch 00386: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1326     \n",
      "Epoch 388/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1351Epoch 00387: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1330     \n",
      "Epoch 389/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1323Epoch 00388: loss improved from 3.13085 to 3.13067, saving model to Donna Files/tagger_weights-improvement-388-3.1307.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1307     \n",
      "Epoch 390/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1351Epoch 00389: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1321     \n",
      "Epoch 391/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1305Epoch 00390: loss improved from 3.13067 to 3.13062, saving model to Donna Files/tagger_weights-improvement-390-3.1306.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1306     \n",
      "Epoch 392/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1313Epoch 00391: loss improved from 3.13062 to 3.13044, saving model to Donna Files/tagger_weights-improvement-391-3.1304.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1304     \n",
      "Epoch 393/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1307Epoch 00392: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1309     \n",
      "Epoch 394/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1266Epoch 00393: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1310     \n",
      "Epoch 395/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1310Epoch 00394: loss improved from 3.13044 to 3.13029, saving model to Donna Files/tagger_weights-improvement-394-3.1303.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1303     \n",
      "Epoch 396/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1311Epoch 00395: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1328     \n",
      "Epoch 397/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1305Epoch 00396: loss improved from 3.13029 to 3.12986, saving model to Donna Files/tagger_weights-improvement-396-3.1299.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1299     \n",
      "Epoch 398/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1265Epoch 00397: loss improved from 3.12986 to 3.12828, saving model to Donna Files/tagger_weights-improvement-397-3.1283.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1283     \n",
      "Epoch 399/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1278Epoch 00398: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1290     \n",
      "Epoch 400/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1309Epoch 00399: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1305     \n",
      "Epoch 401/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1307Epoch 00400: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1304     \n",
      "Epoch 402/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1312Epoch 00401: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1292     \n",
      "Epoch 403/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1311Epoch 00402: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1288     \n",
      "Epoch 404/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1305Epoch 00403: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1289     \n",
      "Epoch 405/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1274Epoch 00404: loss improved from 3.12828 to 3.12790, saving model to Donna Files/tagger_weights-improvement-404-3.1279.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1279     \n",
      "Epoch 406/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1255Epoch 00405: loss improved from 3.12790 to 3.12758, saving model to Donna Files/tagger_weights-improvement-405-3.1276.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1276     \n",
      "Epoch 407/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1291Epoch 00406: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1281     \n",
      "Epoch 408/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1258Epoch 00407: loss improved from 3.12758 to 3.12612, saving model to Donna Files/tagger_weights-improvement-407-3.1261.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1261     \n",
      "Epoch 409/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1290Epoch 00408: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1264     \n",
      "Epoch 410/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1259Epoch 00409: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1269     \n",
      "Epoch 411/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1247Epoch 00410: loss improved from 3.12612 to 3.12423, saving model to Donna Files/tagger_weights-improvement-410-3.1242.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1242     \n",
      "Epoch 412/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1244Epoch 00411: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1245     \n",
      "Epoch 413/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1227Epoch 00412: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1247     \n",
      "Epoch 414/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1254Epoch 00413: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1245     \n",
      "Epoch 415/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1240Epoch 00414: loss improved from 3.12423 to 3.12314, saving model to Donna Files/tagger_weights-improvement-414-3.1231.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1231     \n",
      "Epoch 416/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1226Epoch 00415: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1233     \n",
      "Epoch 417/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1251Epoch 00416: loss improved from 3.12314 to 3.12297, saving model to Donna Files/tagger_weights-improvement-416-3.1230.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1230     \n",
      "Epoch 418/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1228Epoch 00417: loss improved from 3.12297 to 3.12136, saving model to Donna Files/tagger_weights-improvement-417-3.1214.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1214     \n",
      "Epoch 419/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1248Epoch 00418: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1225     \n",
      "Epoch 420/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1213- ETA: 0s - loss: Epoch 00419: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1223     \n",
      "Epoch 421/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1215Epoch 00420: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1214     \n",
      "Epoch 422/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1218Epoch 00421: loss improved from 3.12136 to 3.12072, saving model to Donna Files/tagger_weights-improvement-421-3.1207.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1207     \n",
      "Epoch 423/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1191Epoch 00422: loss improved from 3.12072 to 3.11928, saving model to Donna Files/tagger_weights-improvement-422-3.1193.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1193     \n",
      "Epoch 424/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1204- ETA: 0s - lossEpoch 00423: loss improved from 3.11928 to 3.11860, saving model to Donna Files/tagger_weights-improvement-423-3.1186.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1186     \n",
      "Epoch 425/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1189Epoch 00424: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1195     \n",
      "Epoch 426/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1190Epoch 00425: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1190     \n",
      "Epoch 427/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1189Epoch 00426: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1192     \n",
      "Epoch 428/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1189Epoch 00427: loss improved from 3.11860 to 3.11826, saving model to Donna Files/tagger_weights-improvement-427-3.1183.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1183     \n",
      "Epoch 429/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1178Epoch 00428: loss improved from 3.11826 to 3.11773, saving model to Donna Files/tagger_weights-improvement-428-3.1177.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1177     \n",
      "Epoch 430/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1169Epoch 00429: loss improved from 3.11773 to 3.11766, saving model to Donna Files/tagger_weights-improvement-429-3.1177.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1177     \n",
      "Epoch 431/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1164- ETA: 0s - loss: 3.115Epoch 00430: loss improved from 3.11766 to 3.11475, saving model to Donna Files/tagger_weights-improvement-430-3.1148.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1148     \n",
      "Epoch 432/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1176Epoch 00431: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1174     \n",
      "Epoch 433/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1122Epoch 00432: loss improved from 3.11475 to 3.11415, saving model to Donna Files/tagger_weights-improvement-432-3.1142.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1142     \n",
      "Epoch 434/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1142Epoch 00433: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1157     \n",
      "Epoch 435/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1142Epoch 00434: loss improved from 3.11415 to 3.11306, saving model to Donna Files/tagger_weights-improvement-434-3.1131.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1131     \n",
      "Epoch 436/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1123Epoch 00435: loss improved from 3.11306 to 3.11196, saving model to Donna Files/tagger_weights-improvement-435-3.1120.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1120     \n",
      "Epoch 437/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1093Epoch 00436: loss improved from 3.11196 to 3.11099, saving model to Donna Files/tagger_weights-improvement-436-3.1110.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1110     \n",
      "Epoch 438/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1126Epoch 00437: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1116     \n",
      "Epoch 439/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1121Epoch 00438: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1118     \n",
      "Epoch 440/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1125Epoch 00439: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1138     \n",
      "Epoch 441/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1090Epoch 00440: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1110     \n",
      "Epoch 442/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1080Epoch 00441: loss improved from 3.11099 to 3.10860, saving model to Donna Files/tagger_weights-improvement-441-3.1086.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1086     \n",
      "Epoch 443/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1081Epoch 00442: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1091     \n",
      "Epoch 444/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1095Epoch 00443: loss improved from 3.10860 to 3.10809, saving model to Donna Files/tagger_weights-improvement-443-3.1081.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1081     \n",
      "Epoch 445/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1100Epoch 00444: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1105     \n",
      "Epoch 446/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1070Epoch 00445: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1089     \n",
      "Epoch 447/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1078Epoch 00446: loss improved from 3.10809 to 3.10739, saving model to Donna Files/tagger_weights-improvement-446-3.1074.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1074     \n",
      "Epoch 448/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1036Epoch 00447: loss improved from 3.10739 to 3.10695, saving model to Donna Files/tagger_weights-improvement-447-3.1070.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1070     \n",
      "Epoch 449/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1020Epoch 00448: loss improved from 3.10695 to 3.10468, saving model to Donna Files/tagger_weights-improvement-448-3.1047.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1047     \n",
      "Epoch 450/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1073Epoch 00449: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1052     \n",
      "Epoch 451/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1067Epoch 00450: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1052     \n",
      "Epoch 452/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1015Epoch 00451: loss improved from 3.10468 to 3.10253, saving model to Donna Files/tagger_weights-improvement-451-3.1025.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1025     \n",
      "Epoch 453/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0985Epoch 00452: loss improved from 3.10253 to 3.10064, saving model to Donna Files/tagger_weights-improvement-452-3.1006.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1006     \n",
      "Epoch 454/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0990Epoch 00453: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1012     \n",
      "Epoch 455/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1019Epoch 00454: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.1013     \n",
      "Epoch 456/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0969Epoch 00455: loss improved from 3.10064 to 3.10046, saving model to Donna Files/tagger_weights-improvement-455-3.1005.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.1005     \n",
      "Epoch 457/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.1000Epoch 00456: loss improved from 3.10046 to 3.09943, saving model to Donna Files/tagger_weights-improvement-456-3.0994.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0994     \n",
      "Epoch 458/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0991Epoch 00457: loss improved from 3.09943 to 3.09846, saving model to Donna Files/tagger_weights-improvement-457-3.0985.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0985     \n",
      "Epoch 459/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0952Epoch 00458: loss improved from 3.09846 to 3.09715, saving model to Donna Files/tagger_weights-improvement-458-3.0972.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0972     \n",
      "Epoch 460/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0924Epoch 00459: loss improved from 3.09715 to 3.09389, saving model to Donna Files/tagger_weights-improvement-459-3.0939.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0939     \n",
      "Epoch 461/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0984Epoch 00460: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0988     \n",
      "Epoch 462/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0954Epoch 00461: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0963     \n",
      "Epoch 463/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0983Epoch 00462: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0951     \n",
      "Epoch 464/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0936- ETA: 0s - loss: 3Epoch 00463: loss improved from 3.09389 to 3.09227, saving model to Donna Files/tagger_weights-improvement-463-3.0923.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0923     \n",
      "Epoch 465/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0946Epoch 00464: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0947     \n",
      "Epoch 466/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0964Epoch 00465: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0942     \n",
      "Epoch 467/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0936Epoch 00466: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0958     \n",
      "Epoch 468/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0913Epoch 00467: loss improved from 3.09227 to 3.09003, saving model to Donna Files/tagger_weights-improvement-467-3.0900.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0900     \n",
      "Epoch 469/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0950Epoch 00468: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0960     \n",
      "Epoch 470/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0917Epoch 00469: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0912     \n",
      "Epoch 471/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0907Epoch 00470: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0907     \n",
      "Epoch 472/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0885Epoch 00471: loss improved from 3.09003 to 3.08858, saving model to Donna Files/tagger_weights-improvement-471-3.0886.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0886     \n",
      "Epoch 473/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0896Epoch 00472: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0897     \n",
      "Epoch 474/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0934Epoch 00473: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0908     \n",
      "Epoch 475/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0874Epoch 00474: loss improved from 3.08858 to 3.08746, saving model to Donna Files/tagger_weights-improvement-474-3.0875.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0875     \n",
      "Epoch 476/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0879- ETA: 0s - loss: 3.Epoch 00475: loss improved from 3.08746 to 3.08724, saving model to Donna Files/tagger_weights-improvement-475-3.0872.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0872     \n",
      "Epoch 477/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0865Epoch 00476: loss improved from 3.08724 to 3.08684, saving model to Donna Files/tagger_weights-improvement-476-3.0868.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0868     \n",
      "Epoch 478/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0868Epoch 00477: loss improved from 3.08684 to 3.08661, saving model to Donna Files/tagger_weights-improvement-477-3.0866.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0866     \n",
      "Epoch 479/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0854Epoch 00478: loss improved from 3.08661 to 3.08500, saving model to Donna Files/tagger_weights-improvement-478-3.0850.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0850     \n",
      "Epoch 480/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0811Epoch 00479: loss improved from 3.08500 to 3.08252, saving model to Donna Files/tagger_weights-improvement-479-3.0825.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0825     \n",
      "Epoch 481/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0832Epoch 00480: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0826     \n",
      "Epoch 482/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0849Epoch 00481: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0835     \n",
      "Epoch 483/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0837Epoch 00482: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0831     \n",
      "Epoch 484/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0843Epoch 00483: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0828     \n",
      "Epoch 485/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0817Epoch 00484: loss improved from 3.08252 to 3.08170, saving model to Donna Files/tagger_weights-improvement-484-3.0817.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0817     \n",
      "Epoch 486/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0791Epoch 00485: loss improved from 3.08170 to 3.07940, saving model to Donna Files/tagger_weights-improvement-485-3.0794.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0794     \n",
      "Epoch 487/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0779Epoch 00486: loss improved from 3.07940 to 3.07860, saving model to Donna Files/tagger_weights-improvement-486-3.0786.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0786     \n",
      "Epoch 488/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0804Epoch 00487: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0793     \n",
      "Epoch 489/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0775Epoch 00488: loss improved from 3.07860 to 3.07773, saving model to Donna Files/tagger_weights-improvement-488-3.0777.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0777     \n",
      "Epoch 490/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0756Epoch 00489: loss improved from 3.07773 to 3.07642, saving model to Donna Files/tagger_weights-improvement-489-3.0764.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0764     \n",
      "Epoch 491/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0765Epoch 00490: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0790     \n",
      "Epoch 492/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0736Epoch 00491: loss improved from 3.07642 to 3.07547, saving model to Donna Files/tagger_weights-improvement-491-3.0755.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0755     \n",
      "Epoch 493/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0827Epoch 00492: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0822     \n",
      "Epoch 494/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0793Epoch 00493: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0783     \n",
      "Epoch 495/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0787Epoch 00494: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0755     \n",
      "Epoch 496/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0704Epoch 00495: loss improved from 3.07547 to 3.07218, saving model to Donna Files/tagger_weights-improvement-495-3.0722.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0722     \n",
      "Epoch 497/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0696Epoch 00496: loss improved from 3.07218 to 3.07183, saving model to Donna Files/tagger_weights-improvement-496-3.0718.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0718     \n",
      "Epoch 498/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0723Epoch 00497: loss improved from 3.07183 to 3.07154, saving model to Donna Files/tagger_weights-improvement-497-3.0715.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0715     \n",
      "Epoch 499/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0744Epoch 00498: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0747     \n",
      "Epoch 500/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0663Epoch 00499: loss improved from 3.07154 to 3.06779, saving model to Donna Files/tagger_weights-improvement-499-3.0678.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0678     \n",
      "Epoch 501/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0682Epoch 00500: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0687     \n",
      "Epoch 502/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0700Epoch 00501: loss improved from 3.06779 to 3.06748, saving model to Donna Files/tagger_weights-improvement-501-3.0675.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0675     \n",
      "Epoch 503/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0677Epoch 00502: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0676     \n",
      "Epoch 504/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0688Epoch 00503: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0686     \n",
      "Epoch 505/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0662Epoch 00504: loss improved from 3.06748 to 3.06617, saving model to Donna Files/tagger_weights-improvement-504-3.0662.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0662     \n",
      "Epoch 506/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0695Epoch 00505: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0673     \n",
      "Epoch 507/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0651Epoch 00506: loss improved from 3.06617 to 3.06596, saving model to Donna Files/tagger_weights-improvement-506-3.0660.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0660     \n",
      "Epoch 508/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0645Epoch 00507: loss improved from 3.06596 to 3.06517, saving model to Donna Files/tagger_weights-improvement-507-3.0652.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0652     \n",
      "Epoch 509/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0652Epoch 00508: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0653     \n",
      "Epoch 510/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0612Epoch 00509: loss improved from 3.06517 to 3.06130, saving model to Donna Files/tagger_weights-improvement-509-3.0613.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0613     \n",
      "Epoch 511/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0599Epoch 00510: loss improved from 3.06130 to 3.06008, saving model to Donna Files/tagger_weights-improvement-510-3.0601.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0601     \n",
      "Epoch 512/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0582Epoch 00511: loss improved from 3.06008 to 3.05968, saving model to Donna Files/tagger_weights-improvement-511-3.0597.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0597     \n",
      "Epoch 513/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0595Epoch 00512: loss improved from 3.05968 to 3.05878, saving model to Donna Files/tagger_weights-improvement-512-3.0588.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0588     \n",
      "Epoch 514/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0610Epoch 00513: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0596     \n",
      "Epoch 515/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0566Epoch 00514: loss improved from 3.05878 to 3.05432, saving model to Donna Files/tagger_weights-improvement-514-3.0543.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0543     \n",
      "Epoch 516/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0576Epoch 00515: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0619     \n",
      "Epoch 517/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0568Epoch 00516: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0580     \n",
      "Epoch 518/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0495Epoch 00517: loss improved from 3.05432 to 3.05156, saving model to Donna Files/tagger_weights-improvement-517-3.0516.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0516     \n",
      "Epoch 519/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0567Epoch 00518: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0567     \n",
      "Epoch 520/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0558Epoch 00519: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0559     \n",
      "Epoch 521/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0548Epoch 00520: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0539     \n",
      "Epoch 522/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0544Epoch 00521: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0546     \n",
      "Epoch 523/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0519Epoch 00522: loss improved from 3.05156 to 3.05100, saving model to Donna Files/tagger_weights-improvement-522-3.0510.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0510     \n",
      "Epoch 524/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0525Epoch 00523: loss improved from 3.05100 to 3.05039, saving model to Donna Files/tagger_weights-improvement-523-3.0504.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0504     \n",
      "Epoch 525/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0536Epoch 00524: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0530     \n",
      "Epoch 526/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0426Epoch 00525: loss improved from 3.05039 to 3.04480, saving model to Donna Files/tagger_weights-improvement-525-3.0448.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0448     \n",
      "Epoch 527/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0496Epoch 00526: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0483     \n",
      "Epoch 528/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0514Epoch 00527: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0500     \n",
      "Epoch 529/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0465Epoch 00528: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0450     \n",
      "Epoch 530/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0418Epoch 00529: loss improved from 3.04480 to 3.04170, saving model to Donna Files/tagger_weights-improvement-529-3.0417.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0417     \n",
      "Epoch 531/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0453Epoch 00530: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0449     \n",
      "Epoch 532/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0487Epoch 00531: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0502     \n",
      "Epoch 533/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0416Epoch 00532: loss improved from 3.04170 to 3.04109, saving model to Donna Files/tagger_weights-improvement-532-3.0411.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0411     \n",
      "Epoch 534/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0412Epoch 00533: loss improved from 3.04109 to 3.03938, saving model to Donna Files/tagger_weights-improvement-533-3.0394.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0394     \n",
      "Epoch 535/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0402Epoch 00534: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0405     \n",
      "Epoch 536/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0361Epoch 00535: loss improved from 3.03938 to 3.03917, saving model to Donna Files/tagger_weights-improvement-535-3.0392.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0392     \n",
      "Epoch 537/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0316Epoch 00536: loss improved from 3.03917 to 3.03429, saving model to Donna Files/tagger_weights-improvement-536-3.0343.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0343     \n",
      "Epoch 538/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0355Epoch 00537: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0359     \n",
      "Epoch 539/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0369Epoch 00538: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0368     \n",
      "Epoch 540/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0336Epoch 00539: loss improved from 3.03429 to 3.03353, saving model to Donna Files/tagger_weights-improvement-539-3.0335.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0335     \n",
      "Epoch 541/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0266Epoch 00540: loss improved from 3.03353 to 3.02593, saving model to Donna Files/tagger_weights-improvement-540-3.0259.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0259     \n",
      "Epoch 542/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0264Epoch 00541: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0268     \n",
      "Epoch 543/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0268Epoch 00542: loss improved from 3.02593 to 3.02527, saving model to Donna Files/tagger_weights-improvement-542-3.0253.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0253     \n",
      "Epoch 544/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0269Epoch 00543: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s - loss: 3.0257     \n",
      "Epoch 545/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0284Epoch 00544: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0279     \n",
      "Epoch 546/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0146Epoch 00545: loss improved from 3.02527 to 3.01690, saving model to Donna Files/tagger_weights-improvement-545-3.0169.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0169     \n",
      "Epoch 547/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0213Epoch 00546: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0214     \n",
      "Epoch 548/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0230Epoch 00547: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0209     \n",
      "Epoch 549/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0183Epoch 00548: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0192     \n",
      "Epoch 550/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0175Epoch 00549: loss improved from 3.01690 to 3.01680, saving model to Donna Files/tagger_weights-improvement-549-3.0168.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0168     \n",
      "Epoch 551/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0175Epoch 00550: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0172     \n",
      "Epoch 552/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0142Epoch 00551: loss improved from 3.01680 to 3.01355, saving model to Donna Files/tagger_weights-improvement-551-3.0135.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0135     \n",
      "Epoch 553/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0115Epoch 00552: loss improved from 3.01355 to 3.01130, saving model to Donna Files/tagger_weights-improvement-552-3.0113.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0113     \n",
      "Epoch 554/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0141Epoch 00553: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0148     \n",
      "Epoch 555/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0101Epoch 00554: loss improved from 3.01130 to 3.01064, saving model to Donna Files/tagger_weights-improvement-554-3.0106.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0106     \n",
      "Epoch 556/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0126Epoch 00555: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0125     \n",
      "Epoch 557/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0066Epoch 00556: loss improved from 3.01064 to 3.00609, saving model to Donna Files/tagger_weights-improvement-556-3.0061.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0061     \n",
      "Epoch 558/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0038Epoch 00557: loss improved from 3.00609 to 3.00372, saving model to Donna Files/tagger_weights-improvement-557-3.0037.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0037     \n",
      "Epoch 559/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0056Epoch 00558: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0052     \n",
      "Epoch 560/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0051Epoch 00559: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0056     \n",
      "Epoch 561/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9992Epoch 00560: loss improved from 3.00372 to 3.00036, saving model to Donna Files/tagger_weights-improvement-560-3.0004.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 3.0004     \n",
      "Epoch 562/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0020Epoch 00561: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0031     \n",
      "Epoch 563/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 3.0028Epoch 00562: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 3.0015     \n",
      "Epoch 564/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9978Epoch 00563: loss improved from 3.00036 to 2.99483, saving model to Donna Files/tagger_weights-improvement-563-2.9948.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9948     \n",
      "Epoch 565/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9952Epoch 00564: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9966     \n",
      "Epoch 566/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9992Epoch 00565: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9990     \n",
      "Epoch 567/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9928Epoch 00566: loss improved from 2.99483 to 2.99302, saving model to Donna Files/tagger_weights-improvement-566-2.9930.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9930     \n",
      "Epoch 568/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9847Epoch 00567: loss improved from 2.99302 to 2.98517, saving model to Donna Files/tagger_weights-improvement-567-2.9852.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9852     \n",
      "Epoch 569/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9886Epoch 00568: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9878     \n",
      "Epoch 570/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9783Epoch 00569: loss improved from 2.98517 to 2.97868, saving model to Donna Files/tagger_weights-improvement-569-2.9787.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9787     \n",
      "Epoch 571/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9928Epoch 00570: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9911     \n",
      "Epoch 572/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9806Epoch 00571: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9811     \n",
      "Epoch 573/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9814Epoch 00572: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9819     \n",
      "Epoch 574/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9781Epoch 00573: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9799     \n",
      "Epoch 575/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9720Epoch 00574: loss improved from 2.97868 to 2.97134, saving model to Donna Files/tagger_weights-improvement-574-2.9713.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9713     \n",
      "Epoch 576/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9741Epoch 00575: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9748     \n",
      "Epoch 577/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9715Epoch 00576: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9722     \n",
      "Epoch 578/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9698Epoch 00577: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9723     \n",
      "Epoch 579/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9696Epoch 00578: loss improved from 2.97134 to 2.96917, saving model to Donna Files/tagger_weights-improvement-578-2.9692.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9692     \n",
      "Epoch 580/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9715Epoch 00579: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9702     \n",
      "Epoch 581/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9655Epoch 00580: loss improved from 2.96917 to 2.96436, saving model to Donna Files/tagger_weights-improvement-580-2.9644.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s - loss: 2.9644     \n",
      "Epoch 582/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9601Epoch 00581: loss improved from 2.96436 to 2.95936, saving model to Donna Files/tagger_weights-improvement-581-2.9594.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9594     \n",
      "Epoch 583/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9621Epoch 00582: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9633     \n",
      "Epoch 584/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9515Epoch 00583: loss improved from 2.95936 to 2.95146, saving model to Donna Files/tagger_weights-improvement-583-2.9515.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9515     \n",
      "Epoch 585/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9563Epoch 00584: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9562     \n",
      "Epoch 586/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9560Epoch 00585: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9557     \n",
      "Epoch 587/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9448Epoch 00586: loss improved from 2.95146 to 2.94690, saving model to Donna Files/tagger_weights-improvement-586-2.9469.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9469     \n",
      "Epoch 588/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9481Epoch 00587: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9474     \n",
      "Epoch 589/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9476Epoch 00588: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9477     \n",
      "Epoch 590/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9411Epoch 00589: loss improved from 2.94690 to 2.94451, saving model to Donna Files/tagger_weights-improvement-589-2.9445.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9445     \n",
      "Epoch 591/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9499Epoch 00590: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9489     \n",
      "Epoch 592/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9369Epoch 00591: loss improved from 2.94451 to 2.93669, saving model to Donna Files/tagger_weights-improvement-591-2.9367.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9367     \n",
      "Epoch 593/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9333Epoch 00592: loss improved from 2.93669 to 2.93416, saving model to Donna Files/tagger_weights-improvement-592-2.9342.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9342     \n",
      "Epoch 594/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9316Epoch 00593: loss improved from 2.93416 to 2.93021, saving model to Donna Files/tagger_weights-improvement-593-2.9302.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9302     \n",
      "Epoch 595/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9298Epoch 00594: loss improved from 2.93021 to 2.92769, saving model to Donna Files/tagger_weights-improvement-594-2.9277.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9277     \n",
      "Epoch 596/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9251Epoch 00595: loss improved from 2.92769 to 2.92454, saving model to Donna Files/tagger_weights-improvement-595-2.9245.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9245     \n",
      "Epoch 597/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9270Epoch 00596: loss improved from 2.92454 to 2.92408, saving model to Donna Files/tagger_weights-improvement-596-2.9241.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9241     \n",
      "Epoch 598/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9209Epoch 00597: loss improved from 2.92408 to 2.91973, saving model to Donna Files/tagger_weights-improvement-597-2.9197.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9197     \n",
      "Epoch 599/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9168Epoch 00598: loss improved from 2.91973 to 2.91525, saving model to Donna Files/tagger_weights-improvement-598-2.9152.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9152     \n",
      "Epoch 600/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9090Epoch 00599: loss improved from 2.91525 to 2.90985, saving model to Donna Files/tagger_weights-improvement-599-2.9099.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9099     \n",
      "Epoch 601/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9006Epoch 00600: loss improved from 2.90985 to 2.90286, saving model to Donna Files/tagger_weights-improvement-600-2.9029.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9029     \n",
      "Epoch 602/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9100Epoch 00601: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9098     \n",
      "Epoch 603/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8998Epoch 00602: loss improved from 2.90286 to 2.90123, saving model to Donna Files/tagger_weights-improvement-602-2.9012.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.9012     \n",
      "Epoch 604/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.9014Epoch 00603: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.9026     \n",
      "Epoch 605/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8994Epoch 00604: loss improved from 2.90123 to 2.89891, saving model to Donna Files/tagger_weights-improvement-604-2.8989.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8989     \n",
      "Epoch 606/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8979Epoch 00605: loss improved from 2.89891 to 2.89640, saving model to Donna Files/tagger_weights-improvement-605-2.8964.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8964     \n",
      "Epoch 607/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8838Epoch 00606: loss improved from 2.89640 to 2.88409, saving model to Donna Files/tagger_weights-improvement-606-2.8841.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8841     \n",
      "Epoch 608/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8752Epoch 00607: loss improved from 2.88409 to 2.87520, saving model to Donna Files/tagger_weights-improvement-607-2.8752.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8752     \n",
      "Epoch 609/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8815Epoch 00608: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.8830     \n",
      "Epoch 610/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8745Epoch 00609: loss improved from 2.87520 to 2.87398, saving model to Donna Files/tagger_weights-improvement-609-2.8740.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8740     \n",
      "Epoch 611/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8728Epoch 00610: loss improved from 2.87398 to 2.87240, saving model to Donna Files/tagger_weights-improvement-610-2.8724.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8724     \n",
      "Epoch 612/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8671Epoch 00611: loss improved from 2.87240 to 2.87040, saving model to Donna Files/tagger_weights-improvement-611-2.8704.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8704     \n",
      "Epoch 613/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8580Epoch 00612: loss improved from 2.87040 to 2.85931, saving model to Donna Files/tagger_weights-improvement-612-2.8593.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8593     \n",
      "Epoch 614/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8617- ETA:Epoch 00613: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.8628     \n",
      "Epoch 615/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8440Epoch 00614: loss improved from 2.85931 to 2.84624, saving model to Donna Files/tagger_weights-improvement-614-2.8462.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8462     \n",
      "Epoch 616/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8441Epoch 00615: loss improved from 2.84624 to 2.84372, saving model to Donna Files/tagger_weights-improvement-615-2.8437.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8437     \n",
      "Epoch 617/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8364Epoch 00616: loss improved from 2.84372 to 2.83868, saving model to Donna Files/tagger_weights-improvement-616-2.8387.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8387     \n",
      "Epoch 618/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8358Epoch 00617: loss improved from 2.83868 to 2.83445, saving model to Donna Files/tagger_weights-improvement-617-2.8345.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8345     \n",
      "Epoch 619/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8355Epoch 00618: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.8378     \n",
      "Epoch 620/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8230Epoch 00619: loss improved from 2.83445 to 2.82209, saving model to Donna Files/tagger_weights-improvement-619-2.8221.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8221     \n",
      "Epoch 621/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8294Epoch 00620: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.8298     \n",
      "Epoch 622/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8122Epoch 00621: loss improved from 2.82209 to 2.81241, saving model to Donna Files/tagger_weights-improvement-621-2.8124.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8124     \n",
      "Epoch 623/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8131Epoch 00622: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.8128     \n",
      "Epoch 624/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8135Epoch 00623: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.8141     \n",
      "Epoch 625/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.8051Epoch 00624: loss improved from 2.81241 to 2.80556, saving model to Donna Files/tagger_weights-improvement-624-2.8056.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.8056     \n",
      "Epoch 626/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7931Epoch 00625: loss improved from 2.80556 to 2.79300, saving model to Donna Files/tagger_weights-improvement-625-2.7930.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.7930     \n",
      "Epoch 627/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7816Epoch 00626: loss improved from 2.79300 to 2.78353, saving model to Donna Files/tagger_weights-improvement-626-2.7835.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.7835     \n",
      "Epoch 628/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7805Epoch 00627: loss improved from 2.78353 to 2.78143, saving model to Donna Files/tagger_weights-improvement-627-2.7814.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.7814     \n",
      "Epoch 629/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7780Epoch 00628: loss improved from 2.78143 to 2.77786, saving model to Donna Files/tagger_weights-improvement-628-2.7779.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.7779     \n",
      "Epoch 630/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7783Epoch 00629: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.7780     \n",
      "Epoch 631/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7626Epoch 00630: loss improved from 2.77786 to 2.76341, saving model to Donna Files/tagger_weights-improvement-630-2.7634.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.7634     \n",
      "Epoch 632/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7673Epoch 00631: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.7673     \n",
      "Epoch 633/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7468Epoch 00632: loss improved from 2.76341 to 2.74762, saving model to Donna Files/tagger_weights-improvement-632-2.7476.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.7476     \n",
      "Epoch 634/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7392Epoch 00633: loss improved from 2.74762 to 2.73886, saving model to Donna Files/tagger_weights-improvement-633-2.7389.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.7389     \n",
      "Epoch 635/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7397Epoch 00634: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.7392     \n",
      "Epoch 636/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7412Epoch 00635: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.7418     \n",
      "Epoch 637/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7177Epoch 00636: loss improved from 2.73886 to 2.71900, saving model to Donna Files/tagger_weights-improvement-636-2.7190.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.7190     \n",
      "Epoch 638/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7063Epoch 00637: loss improved from 2.71900 to 2.70593, saving model to Donna Files/tagger_weights-improvement-637-2.7059.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.7059     \n",
      "Epoch 639/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.7172Epoch 00638: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.7190     \n",
      "Epoch 640/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6925Epoch 00639: loss improved from 2.70593 to 2.69315, saving model to Donna Files/tagger_weights-improvement-639-2.6932.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.6932     \n",
      "Epoch 641/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6964Epoch 00640: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.6981     \n",
      "Epoch 642/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6888Epoch 00641: loss improved from 2.69315 to 2.68839, saving model to Donna Files/tagger_weights-improvement-641-2.6884.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.6884     \n",
      "Epoch 643/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6878Epoch 00642: loss improved from 2.68839 to 2.68806, saving model to Donna Files/tagger_weights-improvement-642-2.6881.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.6881     \n",
      "Epoch 644/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6780Epoch 00643: loss improved from 2.68806 to 2.67944, saving model to Donna Files/tagger_weights-improvement-643-2.6794.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.6794     \n",
      "Epoch 645/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6618Epoch 00644: loss improved from 2.67944 to 2.66109, saving model to Donna Files/tagger_weights-improvement-644-2.6611.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.6611     \n",
      "Epoch 646/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6506Epoch 00645: loss improved from 2.66109 to 2.65284, saving model to Donna Files/tagger_weights-improvement-645-2.6528.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.6528     \n",
      "Epoch 647/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6545Epoch 00646: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.6539     \n",
      "Epoch 648/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6269Epoch 00647: loss improved from 2.65284 to 2.62770, saving model to Donna Files/tagger_weights-improvement-647-2.6277.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.6277     \n",
      "Epoch 649/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6409Epoch 00648: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.6395     \n",
      "Epoch 650/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6148Epoch 00649: loss improved from 2.62770 to 2.61294, saving model to Donna Files/tagger_weights-improvement-649-2.6129.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.6129     \n",
      "Epoch 651/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6077Epoch 00650: loss improved from 2.61294 to 2.60977, saving model to Donna Files/tagger_weights-improvement-650-2.6098.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.6098     \n",
      "Epoch 652/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6187Epoch 00651: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.6169     \n",
      "Epoch 653/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.6007Epoch 00652: loss improved from 2.60977 to 2.59925, saving model to Donna Files/tagger_weights-improvement-652-2.5993.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.5993     \n",
      "Epoch 654/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.5803Epoch 00653: loss improved from 2.59925 to 2.58150, saving model to Donna Files/tagger_weights-improvement-653-2.5815.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.5815     \n",
      "Epoch 655/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.5730Epoch 00654: loss improved from 2.58150 to 2.57220, saving model to Donna Files/tagger_weights-improvement-654-2.5722.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.5722     \n",
      "Epoch 656/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.5713Epoch 00655: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.5744     \n",
      "Epoch 657/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.5637Epoch 00656: loss improved from 2.57220 to 2.56538, saving model to Donna Files/tagger_weights-improvement-656-2.5654.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.5654     \n",
      "Epoch 658/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.5518Epoch 00657: loss improved from 2.56538 to 2.55474, saving model to Donna Files/tagger_weights-improvement-657-2.5547.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.5547     \n",
      "Epoch 659/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.5550Epoch 00658: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.5575     \n",
      "Epoch 660/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.5482Epoch 00659: loss improved from 2.55474 to 2.54954, saving model to Donna Files/tagger_weights-improvement-659-2.5495.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.5495     \n",
      "Epoch 661/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.5421Epoch 00660: loss improved from 2.54954 to 2.54052, saving model to Donna Files/tagger_weights-improvement-660-2.5405.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.5405     \n",
      "Epoch 662/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.5194Epoch 00661: loss improved from 2.54052 to 2.51759, saving model to Donna Files/tagger_weights-improvement-661-2.5176.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.5176     \n",
      "Epoch 663/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.5138Epoch 00662: loss improved from 2.51759 to 2.51533, saving model to Donna Files/tagger_weights-improvement-662-2.5153.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.5153     \n",
      "Epoch 664/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4854Epoch 00663: loss improved from 2.51533 to 2.48821, saving model to Donna Files/tagger_weights-improvement-663-2.4882.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.4882     \n",
      "Epoch 665/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4892Epoch 00664: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.4898     \n",
      "Epoch 666/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.5024Epoch 00665: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.5016     \n",
      "Epoch 667/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4693Epoch 00666: loss improved from 2.48821 to 2.46778, saving model to Donna Files/tagger_weights-improvement-666-2.4678.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.4678     \n",
      "Epoch 668/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4757Epoch 00667: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.4776     \n",
      "Epoch 669/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4553Epoch 00668: loss improved from 2.46778 to 2.45513, saving model to Donna Files/tagger_weights-improvement-668-2.4551.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.4551     \n",
      "Epoch 670/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4594Epoch 00669: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.4596     \n",
      "Epoch 671/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4417Epoch 00670: loss improved from 2.45513 to 2.44402, saving model to Donna Files/tagger_weights-improvement-670-2.4440.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.4440     \n",
      "Epoch 672/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4344Epoch 00671: loss improved from 2.44402 to 2.43468, saving model to Donna Files/tagger_weights-improvement-671-2.4347.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.4347     \n",
      "Epoch 673/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4157Epoch 00672: loss improved from 2.43468 to 2.41451, saving model to Donna Files/tagger_weights-improvement-672-2.4145.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.4145     \n",
      "Epoch 674/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4069Epoch 00673: loss improved from 2.41451 to 2.40672, saving model to Donna Files/tagger_weights-improvement-673-2.4067.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.4067     \n",
      "Epoch 675/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4094Epoch 00674: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.4102     \n",
      "Epoch 676/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.4142- ETA: 0s - loss: 2.41Epoch 00675: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.4134     \n",
      "Epoch 677/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.3912Epoch 00676: loss improved from 2.40672 to 2.38946, saving model to Donna Files/tagger_weights-improvement-676-2.3895.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.3895     \n",
      "Epoch 678/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.3788Epoch 00677: loss improved from 2.38946 to 2.37777, saving model to Donna Files/tagger_weights-improvement-677-2.3778.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.3778     \n",
      "Epoch 679/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.3639Epoch 00678: loss improved from 2.37777 to 2.36239, saving model to Donna Files/tagger_weights-improvement-678-2.3624.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.3624     \n",
      "Epoch 680/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.3733Epoch 00679: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.3744     \n",
      "Epoch 681/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.3433Epoch 00680: loss improved from 2.36239 to 2.34424, saving model to Donna Files/tagger_weights-improvement-680-2.3442.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.3442     \n",
      "Epoch 682/1000\n",
      " 9984/10000 [============================>.] - ETA: 0s - loss: 2.3436Epoch 00681: loss improved from 2.34424 to 2.34316, saving model to Donna Files/tagger_weights-improvement-681-2.3432.hdf5\n",
      "10000/10000 [==============================] - 3s - loss: 2.3432     \n",
      "Epoch 683/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.3267Epoch 00682: loss improved from 2.34316 to 2.32626, saving model to Donna Files/tagger_weights-improvement-682-2.3263.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.3263     \n",
      "Epoch 684/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.3269Epoch 00683: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.3283     \n",
      "Epoch 685/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.3131Epoch 00684: loss improved from 2.32626 to 2.31239, saving model to Donna Files/tagger_weights-improvement-684-2.3124.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.3124     \n",
      "Epoch 686/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.2874Epoch 00685: loss improved from 2.31239 to 2.29087, saving model to Donna Files/tagger_weights-improvement-685-2.2909.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.2909     \n",
      "Epoch 687/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.2924- ETA: 0s - loss: Epoch 00686: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.2933     \n",
      "Epoch 688/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.2791Epoch 00687: loss improved from 2.29087 to 2.27928, saving model to Donna Files/tagger_weights-improvement-687-2.2793.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.2793     \n",
      "Epoch 689/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.2789Epoch 00688: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.2800     \n",
      "Epoch 690/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.2516Epoch 00689: loss improved from 2.27928 to 2.25180, saving model to Donna Files/tagger_weights-improvement-689-2.2518.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.2518     \n",
      "Epoch 691/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.2528Epoch 00690: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.2552     \n",
      "Epoch 692/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.2764Epoch 00691: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.2773     \n",
      "Epoch 693/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.2303Epoch 00692: loss improved from 2.25180 to 2.23197, saving model to Donna Files/tagger_weights-improvement-692-2.2320.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.2320     \n",
      "Epoch 694/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.2260Epoch 00693: loss improved from 2.23197 to 2.22559, saving model to Donna Files/tagger_weights-improvement-693-2.2256.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.2256     \n",
      "Epoch 695/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.2026Epoch 00694: loss improved from 2.22559 to 2.20151, saving model to Donna Files/tagger_weights-improvement-694-2.2015.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.2015     \n",
      "Epoch 696/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.2055Epoch 00695: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.2080     \n",
      "Epoch 697/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.1862Epoch 00696: loss improved from 2.20151 to 2.18845, saving model to Donna Files/tagger_weights-improvement-696-2.1885.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.1885     \n",
      "Epoch 698/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.1917Epoch 00697: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.1905     \n",
      "Epoch 699/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.1791Epoch 00698: loss improved from 2.18845 to 2.17939, saving model to Donna Files/tagger_weights-improvement-698-2.1794.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.1794     \n",
      "Epoch 700/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.1598Epoch 00699: loss improved from 2.17939 to 2.16066, saving model to Donna Files/tagger_weights-improvement-699-2.1607.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.1607     \n",
      "Epoch 701/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.1532Epoch 00700: loss improved from 2.16066 to 2.15457, saving model to Donna Files/tagger_weights-improvement-700-2.1546.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.1546     \n",
      "Epoch 702/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.1397Epoch 00701: loss improved from 2.15457 to 2.14122, saving model to Donna Files/tagger_weights-improvement-701-2.1412.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.1412     \n",
      "Epoch 703/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.1635Epoch 00702: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.1642     \n",
      "Epoch 704/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.1270Epoch 00703: loss improved from 2.14122 to 2.12497, saving model to Donna Files/tagger_weights-improvement-703-2.1250.hdf5\n",
      "10000/10000 [==============================] - 3s - loss: 2.1250     \n",
      "Epoch 705/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.1383Epoch 00704: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.1378     \n",
      "Epoch 706/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.0945Epoch 00705: loss improved from 2.12497 to 2.09338, saving model to Donna Files/tagger_weights-improvement-705-2.0934.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.0934     \n",
      "Epoch 707/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.0992Epoch 00706: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.0979     \n",
      "Epoch 708/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.0919Epoch 00707: loss improved from 2.09338 to 2.09027, saving model to Donna Files/tagger_weights-improvement-707-2.0903.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.0903     \n",
      "Epoch 709/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.0763Epoch 00708: loss improved from 2.09027 to 2.07833, saving model to Donna Files/tagger_weights-improvement-708-2.0783.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.0783     \n",
      "Epoch 710/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.0831Epoch 00709: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.0792     \n",
      "Epoch 711/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.0624Epoch 00710: loss improved from 2.07833 to 2.06476, saving model to Donna Files/tagger_weights-improvement-710-2.0648.hdf5\n",
      "10000/10000 [==============================] - 2s - loss: 2.0648     \n",
      "Epoch 712/1000\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 2.0852Epoch 00711: loss did not improve\n",
      "10000/10000 [==============================] - 2s - loss: 2.0873     \n",
      "Epoch 713/1000\n",
      "  128/10000 [..............................] - ETA: 2s - loss: 2.0933"
     ]
    }
   ],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"Donna Files/tagger_weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=1000, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"Donna Files/pos_tagger_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  10000\n"
     ]
    }
   ],
   "source": [
    "# define the checkpoint\n",
    "seq_length = 10\n",
    "dataX = []\n",
    "dataY = []\n",
    "input_line=[]\n",
    "output_line=[]\n",
    "for i in range(10000, 20000, 1):\n",
    "    input_line=train[\"pos_tag_index\"][i:i+seq_length]\n",
    "    output_line=train[\"pos_tag_index\"][i+seq_length]\n",
    "    dataX.append(input_line)\n",
    "    dataY.append(output_line)\n",
    "n_patterns = len(dataX)\n",
    "print \"Total Patterns: \", n_patterns\n",
    "\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (len(dataX), 10, 1))\n",
    "    # normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-d8ce0fe4bd8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "model=load_model(\"Donna Files/pos_tagger_model.h5\")\n",
    "\n",
    "filepath=\"Donna Files/tagger_weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=1000, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"Donna Files/pos_tagger_model.h5\")\n",
    "\n",
    "# load the network weights\n",
    "filename = \"Donna Files/tagger_weights-improvement-997-0.8726.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" Why on earth would you build something like that \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a random seed\n",
    "input_line=\"Why on earth would you build something like that\"\n",
    "pattern = input_line.split()\n",
    "print \"Seed:\"\n",
    "print \"\\\"\", ' '.join([str(value) for value in pattern]), \"\\\"\"\n",
    "indexed_input=[]\n",
    "([indexed_input.append(bag_of_words[value.lower()]) for value in pattern])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern=indexed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern+=list(np.zeros(seq_length-len(pattern)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(seq_length-len(pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "md* ( pps+hvz in dt$ fw-nn fw-nn md* dt$ ( \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(10):\n",
    "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(303)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = np.argmax(prediction)\n",
    "\tresult = index_to_tags[index]\n",
    "\t#seq_in = [index_to_words[value] for value in pattern]\n",
    "\tsys.stdout.write(result+\" \")\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print \"\\nDone.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfcpu",
   "language": "python",
   "name": "tfcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
