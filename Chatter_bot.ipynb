{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Queue import Queue\n",
    "from threading import Thread\n",
    "import subprocess\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from anytree import Node, RenderTree\n",
    "from anytree.dotexport import RenderTreeGraph\n",
    "from anytree import Walker\n",
    "from anytree import Resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class conv_bot(object):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name=name\n",
    "        self.forest=forest()\n",
    "        self.utility_function=\"happy\"\n",
    "        self.emo_model=load_model(\"/home/kavin/Silo/College Work/AI/Donna Files/emotion_classifier_model.h5\")\n",
    "        emo_filename = \"/home/kavin/Silo/College Work/AI/Donna Files/emotion_forward_weights-improvement-00-1.9928.hdf5\"\n",
    "        self.emo_model.load_weights(emo_filename)\n",
    "        self.emo_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "        self.pos_model=load_model(\"/home/kavin/Silo/College Work/AI/Donna Files/pos_tagger_model.h5\")\n",
    "        pos_filename = \"/home/kavin/Silo/College Work/AI/Donna Files/tagger_weights-improvement-997-0.8726.hdf5\"\n",
    "        self.pos_model.load_weights(pos_filename)\n",
    "        self.pos_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "        self.gen_model=load_model(\"/home/kavin/Silo/College Work/AI/Donna Files/text_generator_model.h5\")\n",
    "        gen_filename = \"/home/kavin/Silo/College Work/AI/Donna Files/text_512_lstm_gen_weights-improvement-969-0.0264.hdf5\"\n",
    "        self.gen_model.load_weights(gen_filename)\n",
    "        self.gen_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        self.greet()\n",
    "        \n",
    "    def greet(self):\n",
    "        print(\"Hello. I am \"+self.name+\"!\")\n",
    "    \n",
    "    def session(self):\n",
    "        self.greet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class conversationalist(object):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name=name\n",
    "    \n",
    "    def set_name(self, name):\n",
    "        self._name=name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class forest:\n",
    "    def __init__(self):\n",
    "        self.forest=[]\n",
    "                \n",
    "    def add_tree(self, tree):\n",
    "        self.forest.append(tree)\n",
    "        \n",
    "    def find_tree_w_root(self, node):\n",
    "        for tree in self.forest:\n",
    "            if(tree.root == node):\n",
    "                return tree\n",
    "            \n",
    "    def find_tree_w_node(self, node):\n",
    "        walker=Walker()\n",
    "        paths=[]\n",
    "        for tree in self.forest:\n",
    "            try:\n",
    "                path=walker.walk(tree,node)[-1][-1]\n",
    "                paths.append(path)\n",
    "            except:\n",
    "                pass\n",
    "        if(len(paths)>0):\n",
    "            return(True, paths)\n",
    "        else:\n",
    "            return(False, [])\n",
    "        \n",
    "    def find_tree_w_emotion(self, emo):\n",
    "        trees=[]\n",
    "        #node=Node()\n",
    "        for tree in self.forest:\n",
    "            try:\n",
    "                for child in tree.root.descendants:\n",
    "                    if(child.name==emo):\n",
    "                        trees.append(tree)\n",
    "                        node=child\n",
    "            except:\n",
    "                pass\n",
    "        if(len(trees)>0):\n",
    "            return(True, [trees,child])\n",
    "        else:\n",
    "            return(False, [])\n",
    "        \n",
    "    def print_all_trees(self):\n",
    "        for tree in self.forest:\n",
    "            for pre, fill, node in RenderTree(tree.root):\n",
    "                print(\"%s%s\" % (pre, node.name))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. I am Donna!\n"
     ]
    }
   ],
   "source": [
    "bot=conv_bot(\"Donna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_process():\n",
    "    p = subprocess.Popen(\"bash\", stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=False, universal_newlines=True)\n",
    "    outQueue = Queue()\n",
    "    outThread = Thread(target=\"\", args=(p.stdout, outQueue))\n",
    "    outThread.daemon = True\n",
    "    outThread.start()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predef_questions():\n",
    "    try:\n",
    "        bot_questions=open(\"/home/kavin/Silo/College Work/AI/Donna Files/bot_basic_questions.txt\",'r').readlines()\n",
    "    except:\n",
    "        return True\n",
    "    for question in bot_questions:\n",
    "        if(len(question.strip())>0):\n",
    "            print(bot.name+\": \"+question)\n",
    "            input_line = raw_input(participant.name+\": \")\n",
    "            if( \"name\" in question):\n",
    "                try:\n",
    "                    matched_name=re.match('^(\\w+)$', input_line)\n",
    "                    participant.name=matched_name.group(1)\n",
    "                except:\n",
    "                    matched_name=re.match('.+? (\\w+)$', input_line)\n",
    "                    participant.name=matched_name.group(1)\n",
    "            if(input_line.lower() in [\"exit\", \"quit\", \"stop\", \"bye\"]):\n",
    "                print(\"Goodbye, \"+participant.name+\"!\")\n",
    "                return False        \n",
    "            proc.stdin.write(input_line)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getGeneratedText(input_line, bot):\n",
    "    emotion=predictEmotion(input_line, bot)\n",
    "    target_emotion=steerConversation(emotion, bot)\n",
    "    #pos_pred=getPOSPrediction(input_line, bot)\n",
    "    output_text=generateText(input_line, target_emotion)\n",
    "    return output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictEmotion(input_line, bot):\n",
    "    tweets_x_cols=pd.read_csv(\"/home/kavin/Silo/College Work/AI/DataSets/colum_names.csv\")\n",
    "    input_line_vector=[0]*(len(tweets_x_cols)-1)\n",
    "    for word in input_line:\n",
    "        if(word in list(tweets_x_cols[\"0\"])):\n",
    "            input_line_vector[list(tweets_x_cols[\"0\"]).index(word)]=1\n",
    "    if(sum(input_line_vector)>0):\n",
    "        prediction=bot.emo_model.predict(np.reshape(input_line_vector, (1,len(input_line_vector))))\n",
    "    else:\n",
    "        prediction=0\n",
    "    \n",
    "    with open(\"/home/kavin/Silo/College Work/AI/index_to_emotions.json\") as data_file:    \n",
    "        index_to_emotions = json.load(data_file)\n",
    "    data_file.close()\n",
    "    index_to_emotions[0]=\"Unknown\"\n",
    "    try:\n",
    "        emot=index_to_emotions[str((list(prediction[0]).index(max(prediction[0]))))]\n",
    "    except:\n",
    "        emot=\"Unknown\"        \n",
    "    return emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steerConversation(em, bot):\n",
    "    target=bot.utility_function\n",
    "    forest=bot.forest\n",
    "    flag, tree=forest.find_tree_w_emotion(em)\n",
    "    if(flag):\n",
    "        paths=forest.find_tree_w_node(tree[1])\n",
    "        shortest=min(paths, key=len)\n",
    "        return shortest[1].name\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPOSPrediction(input_line, bot):\n",
    "    #sentence=\"The weather is so nice today\"\n",
    "    pattern = re.split(' |.',input_line)\n",
    "    indexed_input=[]\n",
    "    with open(\"/home/kavin/Silo/College Work/AI/pos_index_to_words.json\") as data_file:    \n",
    "        index_to_words = json.load(data_file)\n",
    "    data_file.close()\n",
    "    with open(\"/home/kavin/Silo/College Work/AI/pos_bag_of_words.json\") as data_file:    \n",
    "        bag_to_words = json.load(data_file)\n",
    "    data_file.close()\n",
    "    try:\n",
    "        ([indexed_input.append(bag_of_words[value.lower()]) for value in pattern])\n",
    "    except:\n",
    "        pass\n",
    "        pattern=indexed_input\n",
    "        pos_list=[]\n",
    "        pattern+=list(np.zeros(int(math.ceil(len(pattern)/float(seq_length))*seq_length)-len(pattern)))\n",
    "        for i in range(10):\n",
    "            x = np.reshape(pattern, (len(pattern)/seq_length, seq_length, 1))\n",
    "            x = x / float(303)\n",
    "            prediction = bot.pos_model.predict(x, verbose=0)\n",
    "            index = np.argmax(prediction)\n",
    "            result = index_to_words[index]\n",
    "            pos_list.append(result)\n",
    "            pattern.append(index)\n",
    "            pattern = pattern[1:len(pattern)]\n",
    "    return pos_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateText(input_line, target_emotion):\n",
    "    pattern = re.split(' |.',input_line)\n",
    "    mov_lines_file=open(\"/home/kavin/Silo/College Work/AI/DataSets/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_lines.txt\",'r')\n",
    "    mov_lines=mov_lines_file.readlines()\n",
    "    dialogues=[]\n",
    "    for mov_line in mov_lines:\n",
    "        matched=re.match('.* \\+\\+\\+\\$\\+\\+\\+ (.+)', mov_line)\n",
    "        dialogues.append(matched.group(1))\n",
    "    tokenized_dialogues=[]\n",
    "    for line in dialogues:\n",
    "        tokenized_dialogues.append(filter(None,re.split(' |!|:|;|\\?|\"|\\-\\-|\\*|<.*?>|</.*?>', line.lower())))\n",
    "    cleaned_dialogues=[]\n",
    "    for line in tokenized_dialogues:\n",
    "        line_list=[]\n",
    "        for token in line:\n",
    "            try:\n",
    "                matched=re.match('([\\*|\\'|_|\\-|\\[]|)(.*)([\\*|\\'|_|\\-|\\]]|)', token)\n",
    "                line_list.append(matched.group(2))\n",
    "            except:\n",
    "                pass\n",
    "        cleaned_dialogues.append(line_list)\n",
    "    all_dialogues=[]\n",
    "    for line in cleaned_dialogues:\n",
    "        all_dialogues+=line\n",
    "    tokens=pd.Series(all_dialogues).unique()\n",
    "    bag_of_words={}\n",
    "    index_to_words={}\n",
    "    index=1\n",
    "    for word in tokens:\n",
    "        bag_of_words[word]=index\n",
    "        index_to_words[index]=word\n",
    "        index+=1\n",
    "    n_vocab = len(tokens)\n",
    "    indexed_input=[]\n",
    "    ([indexed_input.append(bag_of_words[value.lower()]) for value in pattern])\n",
    "    pattern=indexed_input\n",
    "    \n",
    "    pattern+=list(np.zeros(int(math.ceil(len(pattern)/float(seq_length))*seq_length)-len(pattern)))\n",
    "    created_text=\"\"\n",
    "    repeat_flag=True\n",
    "    repeat_count=0\n",
    "    for i in range(10):\n",
    "        for i in range(10):\n",
    "            x = np.reshape(pattern, (len(pattern)/seq_length, seq_length, 1))\n",
    "            x = x / float(n_vocab)\n",
    "            prediction = bot.gen_model.predict(x, verbose=0)\n",
    "            index = np.argmax(prediction)\n",
    "            result = index_to_words[index]\n",
    "            created_text+=result+\" \"\n",
    "            pattern.append(index)\n",
    "            pattern = pattern[1:len(pattern)]\n",
    "        if(predictEmotion(created_text, bot)):\n",
    "            break\n",
    "        \n",
    "    return created_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. I am Donna!\n"
     ]
    }
   ],
   "source": [
    "proc=create_process()\n",
    "bot=conv_bot(\"Donna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donna: What is your name?\n",
      "\n",
      "You: akcian\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-65cde7b795e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparticipant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconversationalist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcontinue_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredef_questions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinue_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\": \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_line\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stop\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"bye\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cf055ed24201>\u001b[0m in \u001b[0;36mpredef_questions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Goodbye, \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mparticipant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "participant=conversationalist(\"You\")\n",
    "continue_flag=predef_questions()\n",
    "while(continue_flag):\n",
    "    input_line = raw_input(participant.name+\": \")\n",
    "    if(input_line.lower() in [\"exit\", \"quit\", \"stop\",\"bye\"]):\n",
    "        print(\"Goodbye, \"+participant.name+\"!\")\n",
    "        continue_flag=False\n",
    "    else:\n",
    "        output = getGeneratedText(input_line, bot)\n",
    "        print(bot.name+\": \"+output)\n",
    "    proc.stdin.write(input_line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
